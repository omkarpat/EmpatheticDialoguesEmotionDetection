{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/omkarpat/EmpatheticDialoguesEmotionDetection/blob/master/Baselines.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 143
    },
    "colab_type": "code",
    "id": "Ed6RYn3sV9d0",
    "outputId": "fcb5945e-525c-4a68-bc65-22026c876fd0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/gdrive\n",
      "/content/gdrive/My Drive/CSE 245 Project\n"
     ]
    }
   ],
   "source": [
    "# Colab settings/mount\n",
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')\n",
    "%cd gdrive/My\\ Drive/CSE\\ 245\\ Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "ybznvtw9WnuJ",
    "outputId": "3c5899fd-b038-4241-b029-db0c05b87690"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Exploration.ipynb\n",
      "data_fixed_train.json\n",
      "data_sample_10.json\n",
      "data_sample_100.json\n",
      "data_sample_100_processed.json\n",
      "data_sample_10_processed.json\n"
     ]
    }
   ],
   "source": [
    "!ls Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "G-95D-Lm_PUt",
    "outputId": "a2476107-f68f-45e9-d988-4b1b06fdf697"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\omkar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: textblob in c:\\users\\omkar\\anaconda3\\lib\\site-packages (0.15.3)\n",
      "Requirement already satisfied: nltk>=3.1 in c:\\users\\omkar\\anaconda3\\lib\\site-packages (from textblob) (3.4.5)\n",
      "Requirement already satisfied: six in c:\\users\\omkar\\anaconda3\\lib\\site-packages (from nltk>=3.1->textblob) (1.13.0)\n",
      "Requirement already satisfied: flair in c:\\users\\omkar\\anaconda3\\lib\\site-packages (0.4.5)\n",
      "Requirement already satisfied: scikit-learn>=0.21.3 in c:\\users\\omkar\\anaconda3\\lib\\site-packages (from flair) (0.22.1)\n",
      "Requirement already satisfied: transformers>=2.3.0 in c:\\users\\omkar\\anaconda3\\lib\\site-packages (from flair) (2.9.1)\n",
      "Requirement already satisfied: sqlitedict>=1.6.0 in c:\\users\\omkar\\anaconda3\\lib\\site-packages (from flair) (1.6.0)\n",
      "Requirement already satisfied: pytest>=5.3.2 in c:\\users\\omkar\\anaconda3\\lib\\site-packages (from flair) (5.3.2)\n",
      "Requirement already satisfied: langdetect in c:\\users\\omkar\\anaconda3\\lib\\site-packages (from flair) (1.0.8)\n",
      "Requirement already satisfied: hyperopt>=0.1.1 in c:\\users\\omkar\\anaconda3\\lib\\site-packages (from flair) (0.2.4)\n",
      "Requirement already satisfied: regex in c:\\users\\omkar\\anaconda3\\lib\\site-packages (from flair) (2020.5.14)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.20 in c:\\users\\omkar\\anaconda3\\lib\\site-packages (from flair) (1.24.3)\n",
      "Requirement already satisfied: torch>=1.1.0 in c:\\users\\omkar\\anaconda3\\lib\\site-packages (from flair) (1.4.0)\n",
      "Requirement already satisfied: deprecated>=1.2.4 in c:\\users\\omkar\\anaconda3\\lib\\site-packages (from flair) (1.2.10)\n",
      "Requirement already satisfied: mpld3==0.3 in c:\\users\\omkar\\anaconda3\\lib\\site-packages (from flair) (0.3)\n",
      "Requirement already satisfied: bpemb>=0.2.9 in c:\\users\\omkar\\anaconda3\\lib\\site-packages (from flair) (0.3.0)\n",
      "Requirement already satisfied: segtok>=1.5.7 in c:\\users\\omkar\\anaconda3\\lib\\site-packages (from flair) (1.5.10)\n",
      "Requirement already satisfied: gensim>=3.4.0 in c:\\users\\omkar\\anaconda3\\lib\\site-packages (from flair) (3.8.3)\n",
      "Requirement already satisfied: matplotlib>=2.2.3 in c:\\users\\omkar\\anaconda3\\lib\\site-packages (from flair) (3.1.1)\n",
      "Requirement already satisfied: tabulate in c:\\users\\omkar\\anaconda3\\lib\\site-packages (from flair) (0.8.7)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in c:\\users\\omkar\\anaconda3\\lib\\site-packages (from flair) (2.8.1)\n",
      "Requirement already satisfied: tqdm>=4.26.0 in c:\\users\\omkar\\anaconda3\\lib\\site-packages (from flair) (4.41.1)\n",
      "Requirement already satisfied: scipy>=0.17.0 in c:\\users\\omkar\\anaconda3\\lib\\site-packages (from scikit-learn>=0.21.3->flair) (1.3.2)\n",
      "Requirement already satisfied: numpy>=1.11.0 in c:\\users\\omkar\\anaconda3\\lib\\site-packages (from scikit-learn>=0.21.3->flair) (1.17.4)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\omkar\\anaconda3\\lib\\site-packages (from scikit-learn>=0.21.3->flair) (0.14.1)\n",
      "Requirement already satisfied: sentencepiece in c:\\users\\omkar\\anaconda3\\lib\\site-packages (from transformers>=2.3.0->flair) (0.1.85)\n",
      "Requirement already satisfied: requests in c:\\users\\omkar\\anaconda3\\lib\\site-packages (from transformers>=2.3.0->flair) (2.22.0)\n",
      "Requirement already satisfied: tokenizers==0.7.0 in c:\\users\\omkar\\anaconda3\\lib\\site-packages (from transformers>=2.3.0->flair) (0.7.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\omkar\\anaconda3\\lib\\site-packages (from transformers>=2.3.0->flair) (3.0.12)\n",
      "Requirement already satisfied: sacremoses in c:\\users\\omkar\\anaconda3\\lib\\site-packages (from transformers>=2.3.0->flair) (0.0.43)\n",
      "Requirement already satisfied: py>=1.5.0 in c:\\users\\omkar\\anaconda3\\lib\\site-packages (from pytest>=5.3.2->flair) (1.8.1)\n",
      "Requirement already satisfied: packaging in c:\\users\\omkar\\anaconda3\\lib\\site-packages (from pytest>=5.3.2->flair) (20.0)\n",
      "Requirement already satisfied: attrs>=17.4.0 in c:\\users\\omkar\\anaconda3\\lib\\site-packages (from pytest>=5.3.2->flair) (19.3.0)\n",
      "Requirement already satisfied: more-itertools>=4.0.0 in c:\\users\\omkar\\anaconda3\\lib\\site-packages (from pytest>=5.3.2->flair) (8.0.2)\n",
      "Requirement already satisfied: pluggy<1.0,>=0.12 in c:\\users\\omkar\\anaconda3\\lib\\site-packages (from pytest>=5.3.2->flair) (0.13.1)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\omkar\\anaconda3\\lib\\site-packages (from pytest>=5.3.2->flair) (0.1.7)\n",
      "Requirement already satisfied: importlib-metadata>=0.12 in c:\\users\\omkar\\anaconda3\\lib\\site-packages (from pytest>=5.3.2->flair) (1.3.0)\n",
      "Requirement already satisfied: atomicwrites>=1.0 in c:\\users\\omkar\\anaconda3\\lib\\site-packages (from pytest>=5.3.2->flair) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\omkar\\anaconda3\\lib\\site-packages (from pytest>=5.3.2->flair) (0.4.3)\n",
      "Requirement already satisfied: six in c:\\users\\omkar\\anaconda3\\lib\\site-packages (from langdetect->flair) (1.13.0)\n",
      "Requirement already satisfied: cloudpickle in c:\\users\\omkar\\anaconda3\\lib\\site-packages (from hyperopt>=0.1.1->flair) (1.2.2)\n",
      "Requirement already satisfied: networkx>=2.2 in c:\\users\\omkar\\anaconda3\\lib\\site-packages (from hyperopt>=0.1.1->flair) (2.4)\n",
      "Requirement already satisfied: future in c:\\users\\omkar\\anaconda3\\lib\\site-packages (from hyperopt>=0.1.1->flair) (0.18.2)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in c:\\users\\omkar\\anaconda3\\lib\\site-packages (from deprecated>=1.2.4->flair) (1.11.2)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in c:\\users\\omkar\\anaconda3\\lib\\site-packages (from gensim>=3.4.0->flair) (2.0.0)\n",
      "Requirement already satisfied: Cython==0.29.14 in c:\\users\\omkar\\anaconda3\\lib\\site-packages (from gensim>=3.4.0->flair) (0.29.14)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\omkar\\anaconda3\\lib\\site-packages (from matplotlib>=2.2.3->flair) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\omkar\\anaconda3\\lib\\site-packages (from matplotlib>=2.2.3->flair) (1.1.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in c:\\users\\omkar\\anaconda3\\lib\\site-packages (from matplotlib>=2.2.3->flair) (2.4.6)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in c:\\users\\omkar\\anaconda3\\lib\\site-packages (from requests->transformers>=2.3.0->flair) (2.8)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in c:\\users\\omkar\\anaconda3\\lib\\site-packages (from requests->transformers>=2.3.0->flair) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\omkar\\anaconda3\\lib\\site-packages (from requests->transformers>=2.3.0->flair) (2019.11.28)\n",
      "Requirement already satisfied: click in c:\\users\\omkar\\anaconda3\\lib\\site-packages (from sacremoses->transformers>=2.3.0->flair) (7.0)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\omkar\\anaconda3\\lib\\site-packages (from importlib-metadata>=0.12->pytest>=5.3.2->flair) (0.6.0)\n",
      "Requirement already satisfied: decorator>=4.3.0 in c:\\users\\omkar\\anaconda3\\lib\\site-packages (from networkx>=2.2->hyperopt>=0.1.1->flair) (4.4.1)\n",
      "Requirement already satisfied: boto3 in c:\\users\\omkar\\anaconda3\\lib\\site-packages (from smart-open>=1.8.1->gensim>=3.4.0->flair) (1.13.11)\n",
      "Requirement already satisfied: boto in c:\\users\\omkar\\anaconda3\\lib\\site-packages (from smart-open>=1.8.1->gensim>=3.4.0->flair) (2.49.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\omkar\\anaconda3\\lib\\site-packages (from kiwisolver>=1.0.1->matplotlib>=2.2.3->flair) (44.0.0.post20200106)\n",
      "Requirement already satisfied: botocore<1.17.0,>=1.16.11 in c:\\users\\omkar\\anaconda3\\lib\\site-packages (from boto3->smart-open>=1.8.1->gensim>=3.4.0->flair) (1.16.11)\n",
      "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in c:\\users\\omkar\\anaconda3\\lib\\site-packages (from boto3->smart-open>=1.8.1->gensim>=3.4.0->flair) (0.3.3)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in c:\\users\\omkar\\anaconda3\\lib\\site-packages (from boto3->smart-open>=1.8.1->gensim>=3.4.0->flair) (0.10.0)\n",
      "Requirement already satisfied: docutils<0.16,>=0.10 in c:\\users\\omkar\\anaconda3\\lib\\site-packages (from botocore<1.17.0,>=1.16.11->boto3->smart-open>=1.8.1->gensim>=3.4.0->flair) (0.15.2)\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('vader_lexicon')\n",
    "!pip install textblob\n",
    "!pip install flair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FPeSFHHvWwwq"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from textblob import TextBlob\n",
    "import flair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 350
    },
    "colab_type": "code",
    "id": "75MkyG4iA9n9",
    "outputId": "8c60e103-80b4-496c-a12c-c8ede180903e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-18 18:04:17,897 loading file C:\\Users\\omkar\\.flair\\models\\imdb-v0.4.pt\n"
     ]
    }
   ],
   "source": [
    "vader = SentimentIntensityAnalyzer()\n",
    "flair_sentiment = flair.models.TextClassifier.load('en-sentiment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pT7Hdi2lW1NR"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19533\n"
     ]
    }
   ],
   "source": [
    "train_data = json.load(open(\"Data/data_fixed_train.json\"))\n",
    "print(len(train_data.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qR81njxAXc-_"
   },
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-94102be9a3f9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    105\u001b[0m     \u001b[0mtrain_data_model1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"|\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline_array_model1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    106\u001b[0m     \u001b[0mtrain_data_model2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"|\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline_array_model2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 107\u001b[1;33m     \u001b[0mtrain_data_model3\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"|\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline_array_model3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    108\u001b[0m     \u001b[0mtrain_data_model4\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"|\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline_array_model4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    109\u001b[0m     '''                             \n",
      "\u001b[1;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "results_data = {}\n",
    "train_data_model1, train_data_model2, train_data_model3, train_data_model4 = [], [], [], []\n",
    "for i,key in enumerate(train_data.keys()):\n",
    "    speaker = train_data[key]['dialog'][0]['speaker']\n",
    "                             \n",
    "    train_data_model1_string = str(train_data[key][\"prompt\"])\n",
    "    train_data_model2_string = str(train_data[key][\"prompt\"]) + \" \" + str(train_data[key]['dialog'][0]['utterance'])\n",
    "    train_data_model3_string = str(train_data[key][\"prompt\"])\n",
    "    train_data_model4_string = str(train_data[key][\"prompt\"])\n",
    "    \n",
    "    for item in train_data[key]['dialog']:\n",
    "        train_data_model4_string += \" \" + str(item['utterance'])\n",
    "        if item['speaker'] == speaker:\n",
    "            train_data_model3_string += \" \" + str(item['utterance'])\n",
    "                             \n",
    "    #train_data_model1.append(train_data_model1_string)\n",
    "    #train_data_model2.append(train_data_model2_string)\n",
    "    #train_data_model3.append(train_data_model3_string)\n",
    "    #train_data_model4.append(train_data_model4_string)\n",
    "    \n",
    "    '''\n",
    "    s1 = flair.data.Sentence(train_data_model1_string)\n",
    "    s2 = flair.data.Sentence(train_data_model2_string)\n",
    "    s3 = flair.data.Sentence(train_data_model3_string)\n",
    "    s4 = flair.data.Sentence(train_data_model4_string)\n",
    "    \n",
    "    flair_sentiment.predict(s1)\n",
    "    flair_sentiment.predict(s2)\n",
    "    flair_sentiment.predict(s3)\n",
    "    flair_sentiment.predict(s4)\n",
    "    \n",
    "    results_data[key] = {\"emotion\": train_data[key][\"emotion\"], \"results\": {\n",
    "      \"model1\" : {\"input\": train_data_model1_string, \"vader\": vader.polarity_scores(train_data_model1_string), \n",
    "                  \"textblob\": TextBlob(train_data_model1_string).sentiment.polarity, \"flair\":s1.labels[0].to_dict()}, \n",
    "      \"model2\" : {\"input\": train_data_model2_string, \"vader\": vader.polarity_scores(train_data_model2_string), \n",
    "                  \"textblob\": TextBlob(train_data_model2_string).sentiment.polarity, \"flair\":s2.labels[0].to_dict()}, \n",
    "      \"model3\" : {\"input\": train_data_model3_string, \"vader\": vader.polarity_scores(train_data_model3_string), \n",
    "                  \"textblob\": TextBlob(train_data_model3_string).sentiment.polarity, \"flair\":s3.labels[0].to_dict()}, \n",
    "      \"model4\" : {\"input\": train_data_model4_string, \"vader\": vader.polarity_scores(train_data_model4_string), \n",
    "                  \"textblob\": TextBlob(train_data_model4_string).sentiment.polarity, \"flair\":s4.labels[0].to_dict()}\n",
    "      }}\n",
    "    \n",
    "    emotion|processed_emotion|text|vader_neg|vader_neu|vader_pos|vader_compound|textblob\n",
    "    \n",
    "    \n",
    "    line_array_model1, line_array_model2, line_array_model3, line_array_model4 = [], [], [], []\n",
    "    \n",
    "    line_array_model1.append(train_data[key][\"emotion\"])\n",
    "    if (train_data[key][\"emotion\"]).lower() in [\"disgusted\",\"devastated\", \"terrified\", \"anxious\", \"furious\", \"embarrassed\",\n",
    "                      \"angry\", \"sad\", \"afraid\", \"annoyed\", \"jealous\", \"ashamed\", \"lonely\", \"guilty\",\n",
    "                      \"apprehensive\", \"disappointed\"]:\n",
    "        line_array_model1.append(\"negative\")\n",
    "    else:\n",
    "        line_array_model1.append(\"positive\")\n",
    "    line_array_model1.append(train_data_model1_string)\n",
    "    line_array_model1.append(str(vader.polarity_scores(train_data_model1_string)[\"neg\"]))\n",
    "    line_array_model1.append(str(vader.polarity_scores(train_data_model1_string)[\"neu\"]))\n",
    "    line_array_model1.append(str(vader.polarity_scores(train_data_model1_string)[\"pos\"]))\n",
    "    line_array_model1.append(str(vader.polarity_scores(train_data_model1_string)[\"compound\"]))\n",
    "    line_array_model1.append(str(TextBlob(train_data_model1_string).sentiment.polarity))\n",
    "                             \n",
    "    line_array_model2.append(train_data[key][\"emotion\"])\n",
    "    if (train_data[key][\"emotion\"]).lower() in [\"disgusted\",\"devastated\", \"terrified\", \"anxious\", \"furious\", \"embarrassed\",\n",
    "                      \"angry\", \"sad\", \"afraid\", \"annoyed\", \"jealous\", \"ashamed\", \"lonely\", \"guilty\",\n",
    "                      \"apprehensive\", \"disappointed\"]:\n",
    "        line_array_model2.append(\"negative\")\n",
    "    else:\n",
    "        line_array_model2.append(\"positive\")\n",
    "    line_array_model2.append(train_data_model2_string)\n",
    "    line_array_model2.append(str(vader.polarity_scores(train_data_model2_string)[\"neg\"]))\n",
    "    line_array_model2.append(str(vader.polarity_scores(train_data_model2_string)[\"neu\"]))\n",
    "    line_array_model2.append(str(vader.polarity_scores(train_data_model2_string)[\"pos\"]))\n",
    "    line_array_model2.append(str(vader.polarity_scores(train_data_model2_string)[\"compound\"]))\n",
    "    line_array_model2.append(str(TextBlob(train_data_model2_string).sentiment.polarity))\n",
    "    '''\n",
    "    line_array_model3.append(train_data[key][\"emotion\"])\n",
    "    if (train_data[key][\"emotion\"]).lower() in [\"disgusted\",\"devastated\", \"terrified\", \"anxious\", \"furious\", \"embarrassed\",\n",
    "                      \"angry\", \"sad\", \"afraid\", \"annoyed\", \"jealous\", \"ashamed\", \"lonely\", \"guilty\",\n",
    "                      \"apprehensive\", \"disappointed\"]:\n",
    "        line_array_model3.append(\"negative\")\n",
    "    else:\n",
    "        line_array_model3.append(\"positive\")\n",
    "    line_array_model3.append(train_data_model3_string)\n",
    "    line_array_model3.append(str(vader.polarity_scores(train_data_model3_string)[\"neg\"]))\n",
    "    line_array_model3.append(str(vader.polarity_scores(train_data_model3_string)[\"neu\"]))\n",
    "    line_array_model3.append(str(vader.polarity_scores(train_data_model3_string)[\"pos\"]))\n",
    "    line_array_model3.append(str(vader.polarity_scores(train_data_model3_string)[\"compound\"]))\n",
    "    line_array_model3.append(str(TextBlob(train_data_model3_string).sentiment.polarity))\n",
    "                             \n",
    "    line_array_model4.append(train_data[key][\"emotion\"])\n",
    "    if (train_data[key][\"emotion\"]).lower() in [\"disgusted\",\"devastated\", \"terrified\", \"anxious\", \"furious\", \"embarrassed\",\n",
    "                      \"angry\", \"sad\", \"afraid\", \"annoyed\", \"jealous\", \"ashamed\", \"lonely\", \"guilty\",\n",
    "                      \"apprehensive\", \"disappointed\"]:\n",
    "        line_array_model4.append(\"negative\")\n",
    "    else:\n",
    "        line_array_model4.append(\"positive\")\n",
    "    line_array_model4.append(train_data_model4_string)\n",
    "    line_array_model4.append(str(vader.polarity_scores(train_data_model4_string)[\"neg\"]))\n",
    "    line_array_model4.append(str(vader.polarity_scores(train_data_model4_string)[\"neu\"]))\n",
    "    line_array_model4.append(str(vader.polarity_scores(train_data_model4_string)[\"pos\"]))\n",
    "    line_array_model4.append(str(vader.polarity_scores(train_data_model4_string)[\"compound\"]))\n",
    "    line_array_model4.append(str(TextBlob(train_data_model4_string).sentiment.polarity))\n",
    "    #print(line_array_model1)\n",
    "    #print(\"|\".join(line_array_model1))\n",
    "    train_data_model1.append(\"|\".join(line_array_model1))\n",
    "    train_data_model2.append(\"|\".join(line_array_model2))\n",
    "    train_data_model3.append(\"|\".join(line_array_model3))\n",
    "    train_data_model4.append(\"|\".join(line_array_model4))\n",
    "    '''                             \n",
    "    if i%1000 == 0:\n",
    "        print(i)\n",
    "        filename = \"Data/data_sample_fixed_processed_\" + str(i) + \".json\"\n",
    "        with open(filename, 'w') as outfile:\n",
    "            outfile.write(json.dumps(results_data, indent=4))\n",
    "            results_data = {}\n",
    "    #print(json.dumps(results_data['1022'], indent=4))\n",
    "    '''\n",
    "filename = \"Data/data_sample_fixed_processed_\" + \"model1\" + \".csv\"\n",
    "with open(filename, 'w') as outfile:\n",
    "    outfile.write(\"emotion|processed_emotion|text|vader_neg|vader_neu|vader_pos|vader_compound|textblob\\n\")\n",
    "    outfile.write(\"\\n\".join(train_data_model1))\n",
    "                             \n",
    "filename = \"Data/data_sample_fixed_processed_\" + \"model2\" + \".csv\"\n",
    "with open(filename, 'w') as outfile:\n",
    "    outfile.write(\"emotion|processed_emotion|text|vader_neg|vader_neu|vader_pos|vader_compound|textblob\\n\")\n",
    "    outfile.write(\"\\n\".join(train_data_model2))\n",
    "                             \n",
    "filename = \"Data/data_sample_fixed_processed_\" + \"model3\" + \".csv\"\n",
    "with open(filename, 'w') as outfile:\n",
    "    outfile.write(\"emotion|processed_emotion|text|vader_neg|vader_neu|vader_pos|vader_compound|textblob\\n\")\n",
    "    for line in train_data_model3:\n",
    "        try:\n",
    "            outfile.write(line)\n",
    "            outfile.write(\"\\n\")\n",
    "        except UnicodeEncodeError:\n",
    "            print(line)\n",
    "                             \n",
    "filename = \"Data/data_sample_fixed_processed_\" + \"model4\" + \".csv\"\n",
    "with open(filename, 'w') as outfile:\n",
    "    outfile.write(\"emotion|processed_emotion|text|vader_neg|vader_neu|vader_pos|vader_compound|textblob\\n\")\n",
    "    for line in train_data_model4:\n",
    "        try:\n",
    "            outfile.write(line)\n",
    "            outfile.write(\"\\n\")\n",
    "        except UnicodeEncodeError:\n",
    "            print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 107
    },
    "colab_type": "code",
    "id": "mZTAnlOycwTs",
    "outputId": "7eeacf75-e183-4840-dcd4-9f7209694ec6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0.127', '0.722', '0.151', '0.1119', '-0.20357142857142857', 'sad|sad|We (family friends) planned a holiday trip to go for the last weekend. I was preparing for that like packing dress and getting ready to it. Unfortunately one of my cousin was unable to come due to his personal reasons. So we just cancelled the trip. I was feeling sad for this trip cancellation. ', '0.0', '0.72', '0.28', '0.5413', '0.25', 'jealous|jealous|My cousin bought a really pretty shirt that I had been wanting.', '0.228', '0.685', '0.088', '-0.6256', '-0.012500000000000011', \"jealous|jealous|I was at the store and I tried on a dress_comma_ and it didn't look good. I saw someone else wearing it_comma_ looking great_comma_ and it made me feel pretty insecure and sad. ]\", '0.0', '1.0', '0.0', '0.0', '0.0', 'caring|caring|I was outside walking one day. And then I found a kitten on the road.', '0.07', '0.553', '0.377', '0.7964', '0.18958333333333333', 'proud|proud|I won first place in the marathon last weekend. I trained hard and deserved the win', '0.0', '1.0', '0.0', '0.0', '0.0', 'ashamed|ashamed|I stole a candy and was called out on it.', '0.4', '0.6', '0.0', '-0.25', '0.0', 'lonely|lonely|i felt all alone yesterday', '0.149', '0.721', '0.13', '-0.1027', '-0.075', 'furious|furious|When I got my test back and my professor had marked everything wrong. I clearly had the correct answers.', '0.0', '1.0', '0.0', '0.0', '0.0', 'excited|excited|I was getting my nose pierced tomorrow!', '0.0', '1.0', '0.0', '0.0', '0.0', 'anxious|anxious|im waiting for bloodwork to come back']\n"
     ]
    }
   ],
   "source": [
    "print(train_data_model1)\n",
    "#print(train_data_model2[0])\n",
    "#print(train_data_model3[0])\n",
    "#print(train_data_model4[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(json.dumps(results_data['1022'], indent=4))\n",
    "with open('Data/data_sample_100_processed.json', 'w') as outfile:\n",
    "    outfile.write(json.dumps(results_data, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion|processed_emotion|text|vader_neg|vader_neu|vader_pos|vader_compound|textblob|flair_value|flair_confidence|model_value|model_confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOcIUQ+LPu7qi5YCcprbQjx",
   "include_colab_link": true,
   "name": "Baselines.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
