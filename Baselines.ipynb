{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Baselines.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/omkarpat/EmpatheticDialoguesEmotionDetection/blob/master/Baselines.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Ed6RYn3sV9d0",
        "outputId": "99ec3c05-7aae-4a33-f8e9-10c0dd18c483",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "# Colab settings/mount\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "%cd gdrive/My\\ Drive/CSE\\ 245\\ Project"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "[Errno 2] No such file or directory: 'gdrive/My Drive/CSE 245 Project'\n",
            "/content/gdrive/My Drive/CSE 245 Project\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ybznvtw9WnuJ",
        "outputId": "9e5a493a-d050-4d32-9968-7f13342d5386",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "!ls Data"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "'Data Exploration.ipynb'   data_sample_10_processed.json\n",
            " data_fixed_train.json\t   fixed_train_516.csv\n",
            " data_sample_100.json\t  'informative words.ipynb'\n",
            " data_sample_10.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "G-95D-Lm_PUt",
        "outputId": "5a69c888-551c-4afc-8c32-bdade17c1d11",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import nltk\n",
        "nltk.download('vader_lexicon')\n",
        "!pip install textblob\n",
        "!pip install flair"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n",
            "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
            "Requirement already satisfied: textblob in /usr/local/lib/python3.6/dist-packages (0.15.3)\n",
            "Requirement already satisfied: nltk>=3.1 in /usr/local/lib/python3.6/dist-packages (from textblob) (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk>=3.1->textblob) (1.12.0)\n",
            "Requirement already satisfied: flair in /usr/local/lib/python3.6/dist-packages (0.4.5)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from flair) (2.8.1)\n",
            "Requirement already satisfied: pytest>=5.3.2 in /usr/local/lib/python3.6/dist-packages (from flair) (5.4.2)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.6/dist-packages (from flair) (0.22.2.post1)\n",
            "Requirement already satisfied: tqdm>=4.26.0 in /usr/local/lib/python3.6/dist-packages (from flair) (4.41.1)\n",
            "Requirement already satisfied: sqlitedict>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from flair) (1.6.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from flair) (2019.12.20)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.20 in /usr/local/lib/python3.6/dist-packages (from flair) (1.24.3)\n",
            "Requirement already satisfied: torch>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from flair) (1.5.0+cu101)\n",
            "Requirement already satisfied: bpemb>=0.2.9 in /usr/local/lib/python3.6/dist-packages (from flair) (0.3.0)\n",
            "Requirement already satisfied: transformers>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from flair) (2.9.1)\n",
            "Requirement already satisfied: gensim>=3.4.0 in /usr/local/lib/python3.6/dist-packages (from flair) (3.6.0)\n",
            "Requirement already satisfied: matplotlib>=2.2.3 in /usr/local/lib/python3.6/dist-packages (from flair) (3.2.1)\n",
            "Requirement already satisfied: mpld3==0.3 in /usr/local/lib/python3.6/dist-packages (from flair) (0.3)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.6/dist-packages (from flair) (0.8.7)\n",
            "Requirement already satisfied: segtok>=1.5.7 in /usr/local/lib/python3.6/dist-packages (from flair) (1.5.10)\n",
            "Requirement already satisfied: langdetect in /usr/local/lib/python3.6/dist-packages (from flair) (1.0.8)\n",
            "Requirement already satisfied: hyperopt>=0.1.1 in /usr/local/lib/python3.6/dist-packages (from flair) (0.1.2)\n",
            "Requirement already satisfied: deprecated>=1.2.4 in /usr/local/lib/python3.6/dist-packages (from flair) (1.2.10)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.6.1->flair) (1.12.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from pytest>=5.3.2->flair) (0.1.9)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from pytest>=5.3.2->flair) (20.3)\n",
            "Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from pytest>=5.3.2->flair) (1.8.1)\n",
            "Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from pytest>=5.3.2->flair) (8.2.0)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.6/dist-packages (from pytest>=5.3.2->flair) (19.3.0)\n",
            "Requirement already satisfied: pluggy<1.0,>=0.12 in /usr/local/lib/python3.6/dist-packages (from pytest>=5.3.2->flair) (0.13.1)\n",
            "Requirement already satisfied: importlib-metadata>=0.12; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from pytest>=5.3.2->flair) (1.6.0)\n",
            "Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.21.3->flair) (1.18.4)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.21.3->flair) (0.14.1)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.21.3->flair) (1.4.1)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch>=1.1.0->flair) (0.16.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from bpemb>=0.2.9->flair) (2.23.0)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from bpemb>=0.2.9->flair) (0.1.90)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers>=2.3.0->flair) (0.7)\n",
            "Requirement already satisfied: tokenizers==0.7.0 in /usr/local/lib/python3.6/dist-packages (from transformers>=2.3.0->flair) (0.7.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers>=2.3.0->flair) (3.0.12)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers>=2.3.0->flair) (0.0.43)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.6/dist-packages (from gensim>=3.4.0->flair) (2.0.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->flair) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->flair) (2.4.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->flair) (1.2.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.6/dist-packages (from hyperopt>=0.1.1->flair) (2.4)\n",
            "Requirement already satisfied: pymongo in /usr/local/lib/python3.6/dist-packages (from hyperopt>=0.1.1->flair) (3.10.1)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.6/dist-packages (from deprecated>=1.2.4->flair) (1.12.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.12; python_version < \"3.8\"->pytest>=5.3.2->flair) (3.1.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->bpemb>=0.2.9->flair) (2020.4.5.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->bpemb>=0.2.9->flair) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->bpemb>=0.2.9->flair) (2.9)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers>=2.3.0->flair) (7.1.2)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim>=3.4.0->flair) (1.13.4)\n",
            "Requirement already satisfied: boto in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim>=3.4.0->flair) (2.49.0)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx->hyperopt>=0.1.1->flair) (4.4.2)\n",
            "Requirement already satisfied: botocore<1.17.0,>=1.16.4 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim>=3.4.0->flair) (1.16.4)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim>=3.4.0->flair) (0.9.5)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim>=3.4.0->flair) (0.3.3)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.17.0,>=1.16.4->boto3->smart-open>=1.2.1->gensim>=3.4.0->flair) (0.15.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "FPeSFHHvWwwq",
        "colab": {}
      },
      "source": [
        "import json\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "from textblob import TextBlob\n",
        "import flair\n",
        "import torch\n",
        "torch.__version__ = '1.5.0'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "75MkyG4iA9n9",
        "outputId": "36da3873-0447-4cf7-fd16-1fcc0244ae94",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "vader = SentimentIntensityAnalyzer()\n",
        "flair_sentiment = flair.models.TextClassifier.load('en-sentiment')"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-05-19 05:49:35,164 loading file /root/.flair/models/imdb-v0.4.pt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "pT7Hdi2lW1NR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "a9b89b1f-33dd-49f9-f8d7-5a70272d1720"
      },
      "source": [
        "train_data = json.load(open(\"Data/data_fixed_train.json\"))\n",
        "print(len(train_data.keys()))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "19533\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "qR81njxAXc-_",
        "colab": {}
      },
      "source": [
        "results_data = {}\n",
        "train_data_model1, train_data_model2, train_data_model3, train_data_model4 = [], [], [], []\n",
        "for i,key in enumerate(train_data.keys()):\n",
        "    speaker = train_data[key]['dialog'][0]['speaker']\n",
        "                             \n",
        "    train_data_model1_string = str(train_data[key][\"prompt\"])\n",
        "    train_data_model2_string = str(train_data[key][\"prompt\"]) + \" \" + str(train_data[key]['dialog'][0]['utterance'])\n",
        "    train_data_model3_string = str(train_data[key][\"prompt\"])\n",
        "    train_data_model4_string = str(train_data[key][\"prompt\"])\n",
        "    \n",
        "    for item in train_data[key]['dialog']:\n",
        "        train_data_model4_string += \" \" + str(item['utterance'])\n",
        "        if item['speaker'] == speaker:\n",
        "            train_data_model3_string += \" \" + str(item['utterance'])\n",
        "                             \n",
        "    #train_data_model1.append(train_data_model1_string)\n",
        "    #train_data_model2.append(train_data_model2_string)\n",
        "    #train_data_model3.append(train_data_model3_string)\n",
        "    #train_data_model4.append(train_data_model4_string)\n",
        "    \n",
        "    s1 = flair.data.Sentence(train_data_model1_string)\n",
        "    s2 = flair.data.Sentence(train_data_model2_string)\n",
        "    s3 = flair.data.Sentence(train_data_model3_string)\n",
        "    s4 = flair.data.Sentence(train_data_model4_string)\n",
        "    \n",
        "    flair_sentiment.predict(s1)\n",
        "    flair_sentiment.predict(s2)\n",
        "    flair_sentiment.predict(s3)\n",
        "    flair_sentiment.predict(s4)\n",
        "    \n",
        "    results_data[key] = {\"emotion\": train_data[key][\"emotion\"], \"results\": {\n",
        "      \"model1\" : {\"input\": train_data_model1_string, \"vader\": vader.polarity_scores(train_data_model1_string), \n",
        "                  \"textblob\": TextBlob(train_data_model1_string).sentiment.polarity, \"flair\":s1.labels[0].to_dict()}, \n",
        "      \"model2\" : {\"input\": train_data_model2_string, \"vader\": vader.polarity_scores(train_data_model2_string), \n",
        "                  \"textblob\": TextBlob(train_data_model2_string).sentiment.polarity, \"flair\":s2.labels[0].to_dict()}, \n",
        "      \"model3\" : {\"input\": train_data_model3_string, \"vader\": vader.polarity_scores(train_data_model3_string), \n",
        "                  \"textblob\": TextBlob(train_data_model3_string).sentiment.polarity, \"flair\":s3.labels[0].to_dict()}, \n",
        "      \"model4\" : {\"input\": train_data_model4_string, \"vader\": vader.polarity_scores(train_data_model4_string), \n",
        "                  \"textblob\": TextBlob(train_data_model4_string).sentiment.polarity, \"flair\":s4.labels[0].to_dict()}\n",
        "      }}\n",
        "    \n",
        "    #emotion|processed_emotion|text|vader_neg|vader_neu|vader_pos|vader_compound|textblob|flair_value|flair_confidence\n",
        "    \n",
        "    line_array_model1, line_array_model2, line_array_model3, line_array_model4 = [], [], [], []\n",
        "    \n",
        "    line_array_model1.append(train_data[key][\"emotion\"])\n",
        "    if (train_data[key][\"emotion\"]).lower() in [\"disgusted\",\"devastated\", \"terrified\", \"anxious\", \"furious\", \"embarrassed\",\n",
        "                      \"angry\", \"sad\", \"afraid\", \"annoyed\", \"jealous\", \"ashamed\", \"lonely\", \"guilty\",\n",
        "                      \"apprehensive\", \"disappointed\"]:\n",
        "        line_array_model1.append(\"negative\")\n",
        "    else:\n",
        "        line_array_model1.append(\"positive\")\n",
        "    line_array_model1.append(train_data_model1_string)\n",
        "    line_array_model1.append(str(vader.polarity_scores(train_data_model1_string)[\"neg\"]))\n",
        "    line_array_model1.append(str(vader.polarity_scores(train_data_model1_string)[\"neu\"]))\n",
        "    line_array_model1.append(str(vader.polarity_scores(train_data_model1_string)[\"pos\"]))\n",
        "    line_array_model1.append(str(vader.polarity_scores(train_data_model1_string)[\"compound\"]))\n",
        "    line_array_model1.append(str(TextBlob(train_data_model1_string).sentiment.polarity))\n",
        "    line_array_model1.append(str(s1.labels[0].to_dict()[\"value\"]))\n",
        "    line_array_model1.append(str(s1.labels[0].to_dict()[\"confidence\"]))\n",
        "                             \n",
        "    line_array_model2.append(train_data[key][\"emotion\"])\n",
        "    if (train_data[key][\"emotion\"]).lower() in [\"disgusted\",\"devastated\", \"terrified\", \"anxious\", \"furious\", \"embarrassed\",\n",
        "                      \"angry\", \"sad\", \"afraid\", \"annoyed\", \"jealous\", \"ashamed\", \"lonely\", \"guilty\",\n",
        "                      \"apprehensive\", \"disappointed\"]:\n",
        "        line_array_model2.append(\"negative\")\n",
        "    else:\n",
        "        line_array_model2.append(\"positive\")\n",
        "    line_array_model2.append(train_data_model2_string)\n",
        "    line_array_model2.append(str(vader.polarity_scores(train_data_model2_string)[\"neg\"]))\n",
        "    line_array_model2.append(str(vader.polarity_scores(train_data_model2_string)[\"neu\"]))\n",
        "    line_array_model2.append(str(vader.polarity_scores(train_data_model2_string)[\"pos\"]))\n",
        "    line_array_model2.append(str(vader.polarity_scores(train_data_model2_string)[\"compound\"]))\n",
        "    line_array_model2.append(str(TextBlob(train_data_model2_string).sentiment.polarity))\n",
        "    line_array_model2.append(str(s2.labels[0].to_dict()[\"value\"]))\n",
        "    line_array_model2.append(str(s2.labels[0].to_dict()[\"confidence\"]))\n",
        "\n",
        "    line_array_model3.append(train_data[key][\"emotion\"])\n",
        "    if (train_data[key][\"emotion\"]).lower() in [\"disgusted\",\"devastated\", \"terrified\", \"anxious\", \"furious\", \"embarrassed\",\n",
        "                      \"angry\", \"sad\", \"afraid\", \"annoyed\", \"jealous\", \"ashamed\", \"lonely\", \"guilty\",\n",
        "                      \"apprehensive\", \"disappointed\"]:\n",
        "        line_array_model3.append(\"negative\")\n",
        "    else:\n",
        "        line_array_model3.append(\"positive\")\n",
        "    line_array_model3.append(train_data_model3_string)\n",
        "    line_array_model3.append(str(vader.polarity_scores(train_data_model3_string)[\"neg\"]))\n",
        "    line_array_model3.append(str(vader.polarity_scores(train_data_model3_string)[\"neu\"]))\n",
        "    line_array_model3.append(str(vader.polarity_scores(train_data_model3_string)[\"pos\"]))\n",
        "    line_array_model3.append(str(vader.polarity_scores(train_data_model3_string)[\"compound\"]))\n",
        "    line_array_model3.append(str(TextBlob(train_data_model3_string).sentiment.polarity))\n",
        "    line_array_model3.append(str(s3.labels[0].to_dict()[\"value\"]))\n",
        "    line_array_model3.append(str(s3.labels[0].to_dict()[\"confidence\"]))\n",
        "                             \n",
        "    line_array_model4.append(train_data[key][\"emotion\"])\n",
        "    if (train_data[key][\"emotion\"]).lower() in [\"disgusted\",\"devastated\", \"terrified\", \"anxious\", \"furious\", \"embarrassed\",\n",
        "                      \"angry\", \"sad\", \"afraid\", \"annoyed\", \"jealous\", \"ashamed\", \"lonely\", \"guilty\",\n",
        "                      \"apprehensive\", \"disappointed\"]:\n",
        "        line_array_model4.append(\"negative\")\n",
        "    else:\n",
        "        line_array_model4.append(\"positive\")\n",
        "    line_array_model4.append(train_data_model4_string)\n",
        "    line_array_model4.append(str(vader.polarity_scores(train_data_model4_string)[\"neg\"]))\n",
        "    line_array_model4.append(str(vader.polarity_scores(train_data_model4_string)[\"neu\"]))\n",
        "    line_array_model4.append(str(vader.polarity_scores(train_data_model4_string)[\"pos\"]))\n",
        "    line_array_model4.append(str(vader.polarity_scores(train_data_model4_string)[\"compound\"]))\n",
        "    line_array_model4.append(str(TextBlob(train_data_model4_string).sentiment.polarity))\n",
        "    #print(line_array_model1)\n",
        "    #print(\"|\".join(line_array_model1))\n",
        "    train_data_model1.append(\"|\".join(line_array_model1))\n",
        "    train_data_model2.append(\"|\".join(line_array_model2))\n",
        "    train_data_model3.append(\"|\".join(line_array_model3))\n",
        "    train_data_model4.append(\"|\".join(line_array_model4))\n",
        "    line_array_model4.append(str(s4.labels[0].to_dict()[\"value\"]))\n",
        "    line_array_model4.append(str(s4.labels[0].to_dict()[\"confidence\"]))\n",
        "                        \n",
        "    if i%1000 == 0:\n",
        "        print(i)\n",
        "        filename = \"Data/data_sample_fixed_processed_\" + str(i) + \".json\"\n",
        "        with open(filename, 'w') as outfile:\n",
        "            outfile.write(json.dumps(results_data, indent=4))\n",
        "            results_data = {}\n",
        "      filename = \"Data/data_sample_fixed_processed_\" + \"model1_\" + str(i) + \".csv\"\n",
        "      with open(filename, 'w') as outfile:\n",
        "          outfile.write(\"emotion|processed_emotion|text|vader_neg|vader_neu|vader_pos|vader_compound|textblob|flair_value|flair_confidence\\n\")\n",
        "          outfile.write(\"\\n\".join(train_data_model1))\n",
        "                                  \n",
        "      filename = \"Data/data_sample_fixed_processed_\" + \"model2_\" + str(i) + \".csv\"\n",
        "      with open(filename, 'w') as outfile:\n",
        "          outfile.write(\"emotion|processed_emotion|text|vader_neg|vader_neu|vader_pos|vader_compound|textblob|flair_value|flair_confidence\\n\")\n",
        "          outfile.write(\"\\n\".join(train_data_model2))\n",
        "                                  \n",
        "      filename = \"Data/data_sample_fixed_processed_\" + \"model3_\" + str(i) + \".csv\"\n",
        "      with open(filename, 'w') as outfile:\n",
        "          outfile.write(\"emotion|processed_emotion|text|vader_neg|vader_neu|vader_pos|vader_compound|textblob|flair_value|flair_confidence\\n\")\n",
        "          for line in train_data_model3:\n",
        "              try:\n",
        "                  outfile.write(line)\n",
        "                  outfile.write(\"\\n\")\n",
        "              except UnicodeEncodeError:\n",
        "                  print(line)\n",
        "                                  \n",
        "      filename = \"Data/data_sample_fixed_processed_\" + \"model4_\" + str(i) + \".csv\"\n",
        "      with open(filename, 'w') as outfile:\n",
        "          outfile.write(\"emotion|processed_emotion|text|vader_neg|vader_neu|vader_pos|vader_compound|textblob|flair_value|flair_confidence\\n\")\n",
        "          for line in train_data_model4:\n",
        "              try:\n",
        "                  outfile.write(line)\n",
        "                  outfile.write(\"\\n\")\n",
        "              except UnicodeEncodeError:\n",
        "                  print(line)\n",
        "\n",
        "filename = \"Data/data_sample_fixed_processed_final.json\"\n",
        "with open(filename, 'w') as outfile:\n",
        "    outfile.write(json.dumps(results_data, indent=4))\n",
        "    results_data = {}\n",
        "filename = \"Data/data_sample_fixed_processed_\" + \"model1_\" + \"final.csv\"\n",
        "with open(filename, 'w') as outfile:\n",
        "    outfile.write(\"emotion|processed_emotion|text|vader_neg|vader_neu|vader_pos|vader_compound|textblob|flair_value|flair_confidence\\n\")\n",
        "    outfile.write(\"\\n\".join(train_data_model1))\n",
        "                            \n",
        "filename = \"Data/data_sample_fixed_processed_\" + \"model2_\" + \"final.csv\"\n",
        "with open(filename, 'w') as outfile:\n",
        "    outfile.write(\"emotion|processed_emotion|text|vader_neg|vader_neu|vader_pos|vader_compound|textblob|flair_value|flair_confidence\\n\")\n",
        "    outfile.write(\"\\n\".join(train_data_model2))\n",
        "                            \n",
        "filename = \"Data/data_sample_fixed_processed_\" + \"model3_\" + \"final.csv\"\n",
        "with open(filename, 'w') as outfile:\n",
        "    outfile.write(\"emotion|processed_emotion|text|vader_neg|vader_neu|vader_pos|vader_compound|textblob|flair_value|flair_confidence\\n\")\n",
        "    for line in train_data_model3:\n",
        "        try:\n",
        "            outfile.write(line)\n",
        "            outfile.write(\"\\n\")\n",
        "        except UnicodeEncodeError:\n",
        "            print(line)\n",
        "                            \n",
        "filename = \"Data/data_sample_fixed_processed_\" + \"model4_\" + \"final.csv\"\n",
        "with open(filename, 'w') as outfile:\n",
        "    outfile.write(\"emotion|processed_emotion|text|vader_neg|vader_neu|vader_pos|vader_compound|textblob|flair_value|flair_confidence\\n\")\n",
        "    for line in train_data_model4:\n",
        "        try:\n",
        "            outfile.write(line)\n",
        "            outfile.write(\"\\n\")\n",
        "        except UnicodeEncodeError:\n",
        "            print(line)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "mZTAnlOycwTs",
        "outputId": "7eeacf75-e183-4840-dcd4-9f7209694ec6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        }
      },
      "source": [
        "print(train_data_model1)\n",
        "#print(train_data_model2[0])\n",
        "#print(train_data_model3[0])\n",
        "#print(train_data_model4[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['0.127', '0.722', '0.151', '0.1119', '-0.20357142857142857', 'sad|sad|We (family friends) planned a holiday trip to go for the last weekend. I was preparing for that like packing dress and getting ready to it. Unfortunately one of my cousin was unable to come due to his personal reasons. So we just cancelled the trip. I was feeling sad for this trip cancellation. ', '0.0', '0.72', '0.28', '0.5413', '0.25', 'jealous|jealous|My cousin bought a really pretty shirt that I had been wanting.', '0.228', '0.685', '0.088', '-0.6256', '-0.012500000000000011', \"jealous|jealous|I was at the store and I tried on a dress_comma_ and it didn't look good. I saw someone else wearing it_comma_ looking great_comma_ and it made me feel pretty insecure and sad. ]\", '0.0', '1.0', '0.0', '0.0', '0.0', 'caring|caring|I was outside walking one day. And then I found a kitten on the road.', '0.07', '0.553', '0.377', '0.7964', '0.18958333333333333', 'proud|proud|I won first place in the marathon last weekend. I trained hard and deserved the win', '0.0', '1.0', '0.0', '0.0', '0.0', 'ashamed|ashamed|I stole a candy and was called out on it.', '0.4', '0.6', '0.0', '-0.25', '0.0', 'lonely|lonely|i felt all alone yesterday', '0.149', '0.721', '0.13', '-0.1027', '-0.075', 'furious|furious|When I got my test back and my professor had marked everything wrong. I clearly had the correct answers.', '0.0', '1.0', '0.0', '0.0', '0.0', 'excited|excited|I was getting my nose pierced tomorrow!', '0.0', '1.0', '0.0', '0.0', '0.0', 'anxious|anxious|im waiting for bloodwork to come back']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_DQy3oR7ejcC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#print(json.dumps(results_data['1022'], indent=4))\n",
        "with open('Data/data_sample_100_processed.json', 'w') as outfile:\n",
        "    outfile.write(json.dumps(results_data, indent=4))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4hwMRjRdejcJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "emotion|processed_emotion|text|vader_neg|vader_neu|vader_pos|vader_compound|textblob|flair_value|flair_confidence|model_value|model_confidence"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L8nZRxKiejcQ",
        "colab_type": "code",
        "colab": {},
        "outputId": "7ec52ad7-82ba-4ec7-ec0b-44d75c61ba72"
      },
      "source": [
        "import torch\n",
        "print(torch.__version__)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.4.0\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}