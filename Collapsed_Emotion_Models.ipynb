{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Collapsed Emotion Models.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOk+7Ke+s/uUgzgeNv91bGU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "8a6dab2b8359474dbeb2ae70ec95a576": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_f1f192c82af74853bb6176a464f1e8c2",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_650716fce6c846a6b89ef3b7a3586f5d",
              "IPY_MODEL_b1560c694ff14ce0abc8d8cd1c8dde96"
            ]
          }
        },
        "f1f192c82af74853bb6176a464f1e8c2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "650716fce6c846a6b89ef3b7a3586f5d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_6a0668a2bb094f50a11fc9c79b4623bb",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_73be189ffeb04de8ac532ff5547c8b5e"
          }
        },
        "b1560c694ff14ce0abc8d8cd1c8dde96": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_8fba8914374945c885fdd64379a452fa",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 232k/232k [00:00&lt;00:00, 803kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_60f3a643da094e0ebbb706ab0da9deb7"
          }
        },
        "6a0668a2bb094f50a11fc9c79b4623bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "73be189ffeb04de8ac532ff5547c8b5e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8fba8914374945c885fdd64379a452fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "60f3a643da094e0ebbb706ab0da9deb7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/omkarpat/EmpatheticDialoguesEmotionDetection/blob/master/Collapsed_Emotion_Models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NTgQF4ZZ8aY4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 935
        },
        "outputId": "5895612f-e6b1-4dba-c4d9-a8547e4199f0"
      },
      "source": [
        "# Colab settings/mount\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "%cd gdrive/My\\ Drive/CSE\\ 245\\ Project\n",
        "#check if drive is loaded successfully\n",
        "!ls Data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n",
            "/content/gdrive/My Drive/CSE 245 Project\n",
            "'Data Exploration.ipynb'\n",
            " data_fixed_train_complement_analysis.csv\n",
            " data_fixed_train.json\n",
            " data_sample_100.json\n",
            " data_sample_10_complement_analysis.csv\n",
            " data_sample_10.json\n",
            " data_sample_10_processed.json\n",
            " data_sample_fixed_processed_final.json\n",
            " data_sample_fixed_processed_model1_final.csv\n",
            " data_sample_fixed_processed_model2_final.csv\n",
            " data_sample_fixed_processed_model3_final.csv\n",
            " data_sample_fixed_processed_model4_final.csv\n",
            " fixed\n",
            " fixed_test.csv\n",
            " fixed_test.json\n",
            " fixed_train_516.csv\n",
            " fixed_valid.csv\n",
            " fixed_valid.json\n",
            "'informative words.ipynb'\n",
            " model1_predictions_test.csv\n",
            " model1_predictions_train.csv\n",
            " model1_predictions_valid.csv\n",
            " model2_predictions_test.csv\n",
            " model2_predictions_train.csv\n",
            " model2_predictions_valid.csv\n",
            " model3_predictions_test.csv\n",
            " model3_predictions_train.csv\n",
            " model3_predictions_valid.csv\n",
            " model4_predictions_test.csv\n",
            " model4_predictions_train.csv\n",
            " model4_predictions_valid.csv\n",
            "'Model Metrics.gsheet'\n",
            " Raw\n",
            " test_fixed_processed_final.json\n",
            " test_fixed_processed_model1_final.csv\n",
            " test_fixed_processed_model2_final.csv\n",
            " test_fixed_processed_model3_final.csv\n",
            " test_fixed_processed_model4_final.csv\n",
            " valence_groupings.txt\n",
            " valid.csv\n",
            " valid_fixed_processed_final.json\n",
            " valid_fixed_processed_model1_final.csv\n",
            " valid_fixed_processed_model2_final.csv\n",
            " valid_fixed_processed_model3_final.csv\n",
            " valid_fixed_processed_model4_final.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yf-vJF0X8wer",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 615
        },
        "outputId": "0009799c-f530-4477-950e-093245f118ce"
      },
      "source": [
        "# install supporting libraries\n",
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9c/35/1c3f6e62d81f5f0daff1384e6d5e6c5758682a8357ebc765ece2b9def62b/transformers-3.0.0-py3-none-any.whl (754kB)\n",
            "\r\u001b[K     |▍                               | 10kB 24.0MB/s eta 0:00:01\r\u001b[K     |▉                               | 20kB 3.0MB/s eta 0:00:01\r\u001b[K     |█▎                              | 30kB 4.0MB/s eta 0:00:01\r\u001b[K     |█▊                              | 40kB 4.3MB/s eta 0:00:01\r\u001b[K     |██▏                             | 51kB 3.5MB/s eta 0:00:01\r\u001b[K     |██▋                             | 61kB 3.9MB/s eta 0:00:01\r\u001b[K     |███                             | 71kB 4.2MB/s eta 0:00:01\r\u001b[K     |███▌                            | 81kB 4.6MB/s eta 0:00:01\r\u001b[K     |████                            | 92kB 4.9MB/s eta 0:00:01\r\u001b[K     |████▍                           | 102kB 4.6MB/s eta 0:00:01\r\u001b[K     |████▊                           | 112kB 4.6MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 122kB 4.6MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 133kB 4.6MB/s eta 0:00:01\r\u001b[K     |██████                          | 143kB 4.6MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 153kB 4.6MB/s eta 0:00:01\r\u001b[K     |███████                         | 163kB 4.6MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 174kB 4.6MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 184kB 4.6MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 194kB 4.6MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 204kB 4.6MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 215kB 4.6MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 225kB 4.6MB/s eta 0:00:01\r\u001b[K     |██████████                      | 235kB 4.6MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 245kB 4.6MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 256kB 4.6MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 266kB 4.6MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 276kB 4.6MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 286kB 4.6MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 296kB 4.6MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 307kB 4.6MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 317kB 4.6MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 327kB 4.6MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 337kB 4.6MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 348kB 4.6MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 358kB 4.6MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 368kB 4.6MB/s eta 0:00:01\r\u001b[K     |████████████████                | 378kB 4.6MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 389kB 4.6MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 399kB 4.6MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 409kB 4.6MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 419kB 4.6MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 430kB 4.6MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 440kB 4.6MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 450kB 4.6MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 460kB 4.6MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 471kB 4.6MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 481kB 4.6MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 491kB 4.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 501kB 4.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 512kB 4.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 522kB 4.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 532kB 4.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 542kB 4.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 552kB 4.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 563kB 4.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 573kB 4.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 583kB 4.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 593kB 4.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 604kB 4.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 614kB 4.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 624kB 4.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 634kB 4.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 645kB 4.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 655kB 4.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 665kB 4.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 675kB 4.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 686kB 4.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 696kB 4.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 706kB 4.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 716kB 4.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 727kB 4.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 737kB 4.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 747kB 4.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 757kB 4.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Collecting tokenizers==0.8.0-rc4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e8/bd/e5abec46af977c8a1375c1dca7cb1e5b3ec392ef279067af7f6bc50491a0/tokenizers-0.8.0rc4-cp36-cp36m-manylinux1_x86_64.whl (3.0MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0MB 24.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 45.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 57.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (1.12.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.9)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.15.1)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893260 sha256=b409e01a48cdbb0f88bf0a18463bd165a3fe0555686b51c571ac763b9c19f198\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: tokenizers, sentencepiece, sacremoses, transformers\n",
            "Successfully installed sacremoses-0.0.43 sentencepiece-0.1.91 tokenizers-0.8.0rc4 transformers-3.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jRUJYnuo8xrl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "d6148e9d-bd99-42f6-d656-e41b1b175b3b"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Get the GPU device name.\n",
        "device_name = tf.test.gpu_device_name()\n",
        "\n",
        "# The device name should look like the following:\n",
        "if device_name == '/device:GPU:0':\n",
        "    print('Found GPU at: {}'.format(device_name))\n",
        "else:\n",
        "    raise SystemError('GPU device not found')\n",
        "\n",
        "import torch\n",
        "\n",
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():    \n",
        "\n",
        "    # Tell PyTorch to use the GPU.    \n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n",
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla P100-PCIE-16GB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z9cRiERe81gw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset_name = \"model2\"\n",
        "model_name = \"model2\"\n",
        "model_type = \"collapsed_emotion\" #pos_neg or emotion or valence or collapsed_emotion"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LCOyGePr8_Ui",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "train_filename = \"Data/data_sample_fixed_processed_\" + dataset_name + \"_final.csv\"\n",
        "valid_filename = \"Data/valid_fixed_processed_\" + dataset_name + \"_final.csv\"\n",
        "test_filename = \"Data/test_fixed_processed_\" + dataset_name + \"_final.csv\"\n",
        "\n",
        "train_df = pd.read_csv(train_filename, sep='|', error_bad_lines=False)\n",
        "train_df = train_df.dropna()\n",
        "valid_df = pd.read_csv(valid_filename, sep='|', error_bad_lines=False)\n",
        "valid_df = valid_df.dropna()\n",
        "test_df = pd.read_csv(test_filename, sep='|', error_bad_lines=False)\n",
        "test_df = test_df.dropna()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rjFYimA39JPX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "category2index = {\n",
        "    \"sentimental\":1,\n",
        "    \"sad\":2,\n",
        "    \"devastated\":2,\n",
        "    \"hopeful\":3,\n",
        "    \"joyful\":4,\n",
        "    \"impressed\":5,\n",
        "    \"terrified\":6,\n",
        "    \"afraid\":6,\n",
        "    \"proud\":7,\n",
        "    \"grateful\":8,\n",
        "    \"lonely\":9,\n",
        "    \"surprised\":10,\n",
        "    \"anxious\":11,\n",
        "    \"guilty\":12,\n",
        "    \"trusting\":13,\n",
        "    \"nostalgic\":14,\n",
        "    \"excited\":15,\n",
        "    \"disgusted\":16,\n",
        "    \"caring\":17,\n",
        "    \"furious\":18,\n",
        "    \"angry\":18,\n",
        "    \"prepared\":19,\n",
        "    \"disappointed\":20,\n",
        "    \"faithful\":21,\n",
        "    \"confident\":22,\n",
        "    \"apprehensive\":23,\n",
        "    \"jealous\":24,\n",
        "    \"embarrassed\":25,\n",
        "    \"annoyed\":26,\n",
        "    \"ashamed\":27,\n",
        "    \"content\":28,\n",
        "    \"anticipating\":29\n",
        "}\n",
        "index2category = {}\n",
        "for key, value in category2index.items():\n",
        "  index2category[value] = key\n",
        "\n",
        "def category2label(category):\n",
        "  for key in category2index.keys():\n",
        "    if key == category:\n",
        "      return category2index[key]\n",
        "  print(category)\n",
        "  return None\n",
        "\n",
        "def label2emotion(labels):\n",
        "  valence_list = []\n",
        "  for label in labels:\n",
        "    valence_list.append(index2category[label])\n",
        "  return valence_list\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V5gLaUrwECbj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 462
        },
        "outputId": "81aa8d82-0bb5-4f31-b5e4-4dd9541b851e"
      },
      "source": [
        "print('Number of training sentences: {:,}\\n'.format(train_df.shape[0]))\n",
        "print('Number of valid sentences: {:,}\\n'.format(valid_df.shape[0]))\n",
        "print('Number of test sentences: {:,}\\n'.format(test_df.shape[0]))\n",
        "\n",
        "train_df['label'] = train_df['emotion'].apply(lambda x: int(category2label(x.lower())))\n",
        "valid_df['label'] = valid_df['emotion'].apply(lambda x: int(category2label(x.lower())))\n",
        "test_df['label'] = test_df['emotion'].apply(lambda x: int(category2label(x.lower())))\n",
        "\n",
        "# Display 10 random rows from the data.\n",
        "train_df.sample(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training sentences: 19,533\n",
            "\n",
            "Number of valid sentences: 2,758\n",
            "\n",
            "Number of test sentences: 2,538\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>emotion</th>\n",
              "      <th>processed_emotion</th>\n",
              "      <th>text</th>\n",
              "      <th>vader_neg</th>\n",
              "      <th>vader_neu</th>\n",
              "      <th>vader_pos</th>\n",
              "      <th>vader_compound</th>\n",
              "      <th>textblob</th>\n",
              "      <th>flair_value</th>\n",
              "      <th>flair_confidence</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>5800</th>\n",
              "      <td>impressed</td>\n",
              "      <td>positive</td>\n",
              "      <td>My tattoo artist really made my new tattoo pop...</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.804</td>\n",
              "      <td>0.196</td>\n",
              "      <td>0.7650</td>\n",
              "      <td>0.307273</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>0.975753</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4539</th>\n",
              "      <td>embarrassed</td>\n",
              "      <td>negative</td>\n",
              "      <td>I passed gas while on my first date with a gir...</td>\n",
              "      <td>0.070</td>\n",
              "      <td>0.930</td>\n",
              "      <td>0.000</td>\n",
              "      <td>-0.3400</td>\n",
              "      <td>0.037500</td>\n",
              "      <td>NEGATIVE</td>\n",
              "      <td>0.900509</td>\n",
              "      <td>25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8049</th>\n",
              "      <td>proud</td>\n",
              "      <td>positive</td>\n",
              "      <td>I was eating lunch with family the other day a...</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.810</td>\n",
              "      <td>0.190</td>\n",
              "      <td>0.8020</td>\n",
              "      <td>0.183333</td>\n",
              "      <td>NEGATIVE</td>\n",
              "      <td>0.989474</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17019</th>\n",
              "      <td>surprised</td>\n",
              "      <td>positive</td>\n",
              "      <td>I was happily shocked my aunt got me a laptop....</td>\n",
              "      <td>0.135</td>\n",
              "      <td>0.674</td>\n",
              "      <td>0.191</td>\n",
              "      <td>0.4404</td>\n",
              "      <td>-0.233333</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>0.997043</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18143</th>\n",
              "      <td>lonely</td>\n",
              "      <td>negative</td>\n",
              "      <td>I moved an hour away from my sister. We lived ...</td>\n",
              "      <td>0.000</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>-0.008333</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>0.999934</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1487</th>\n",
              "      <td>sad</td>\n",
              "      <td>negative</td>\n",
              "      <td>Today is my last day working. I am going to mi...</td>\n",
              "      <td>0.127</td>\n",
              "      <td>0.873</td>\n",
              "      <td>0.000</td>\n",
              "      <td>-0.2960</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>0.645867</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6115</th>\n",
              "      <td>confident</td>\n",
              "      <td>positive</td>\n",
              "      <td>I think the Eagles can win the superbowl again...</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.650</td>\n",
              "      <td>0.350</td>\n",
              "      <td>0.9323</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>0.794800</td>\n",
              "      <td>22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5537</th>\n",
              "      <td>hopeful</td>\n",
              "      <td>positive</td>\n",
              "      <td>i know ill make it this time i failed ajob tes...</td>\n",
              "      <td>0.444</td>\n",
              "      <td>0.556</td>\n",
              "      <td>0.000</td>\n",
              "      <td>-0.8316</td>\n",
              "      <td>-0.375000</td>\n",
              "      <td>NEGATIVE</td>\n",
              "      <td>0.999944</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1469</th>\n",
              "      <td>confident</td>\n",
              "      <td>positive</td>\n",
              "      <td>I am confident that I will find a job soon I h...</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.775</td>\n",
              "      <td>0.225</td>\n",
              "      <td>0.4939</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>0.571378</td>\n",
              "      <td>22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18253</th>\n",
              "      <td>embarrassed</td>\n",
              "      <td>negative</td>\n",
              "      <td>Once in elementary school my skirt ripped in f...</td>\n",
              "      <td>0.118</td>\n",
              "      <td>0.745</td>\n",
              "      <td>0.137</td>\n",
              "      <td>0.1950</td>\n",
              "      <td>-0.150000</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>0.873531</td>\n",
              "      <td>25</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           emotion processed_emotion  ... flair_confidence  label\n",
              "5800     impressed          positive  ...         0.975753      5\n",
              "4539   embarrassed          negative  ...         0.900509     25\n",
              "8049         proud          positive  ...         0.989474      7\n",
              "17019    surprised          positive  ...         0.997043     10\n",
              "18143       lonely          negative  ...         0.999934      9\n",
              "1487           sad          negative  ...         0.645867      2\n",
              "6115     confident          positive  ...         0.794800     22\n",
              "5537       hopeful          positive  ...         0.999944      3\n",
              "1469     confident          positive  ...         0.571378     22\n",
              "18253  embarrassed          negative  ...         0.873531     25\n",
              "\n",
              "[10 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S0vvfYr-EE7n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentences_train = train_df.text.values\n",
        "labels_train = train_df.label.values\n",
        "sentences_valid = valid_df.text.values\n",
        "labels_valid = valid_df.label.values\n",
        "sentences_test = test_df.text.values\n",
        "labels_test = test_df.label.values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ygzkg2ikEICd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84,
          "referenced_widgets": [
            "8a6dab2b8359474dbeb2ae70ec95a576",
            "f1f192c82af74853bb6176a464f1e8c2",
            "650716fce6c846a6b89ef3b7a3586f5d",
            "b1560c694ff14ce0abc8d8cd1c8dde96",
            "6a0668a2bb094f50a11fc9c79b4623bb",
            "73be189ffeb04de8ac532ff5547c8b5e",
            "8fba8914374945c885fdd64379a452fa",
            "60f3a643da094e0ebbb706ab0da9deb7"
          ]
        },
        "outputId": "93fb4ed1-6f20-4eed-f6a2-2ae31250d617"
      },
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "# Load the BERT tokenizer.\n",
        "print('Loading BERT tokenizer...')\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading BERT tokenizer...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8a6dab2b8359474dbeb2ae70ec95a576",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fwYWc9tjENqs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "f98c366a-2d78-40ba-cb12-8f6123795fe1"
      },
      "source": [
        "# Print the original sentence.\n",
        "print(' Original: ', sentences_train[0])\n",
        "\n",
        "# Print the sentence split into tokens.\n",
        "print('Tokenized: ', tokenizer.tokenize(sentences_train[0]))\n",
        "\n",
        "# Print the sentence mapped to token ids.\n",
        "print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(sentences_train[0])))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Original:  I remember going to the fireworks with my best friend. There was a lot of people_comma_ but it only felt like us in the world. I remember going to see the fireworks with my best friend. It was the first time we ever spent time alone together. Although there was a lot of people_comma_ we felt like the only people in the world.\n",
            "Tokenized:  ['i', 'remember', 'going', 'to', 'the', 'fireworks', 'with', 'my', 'best', 'friend', '.', 'there', 'was', 'a', 'lot', 'of', 'people', '_', 'com', '##ma', '_', 'but', 'it', 'only', 'felt', 'like', 'us', 'in', 'the', 'world', '.', 'i', 'remember', 'going', 'to', 'see', 'the', 'fireworks', 'with', 'my', 'best', 'friend', '.', 'it', 'was', 'the', 'first', 'time', 'we', 'ever', 'spent', 'time', 'alone', 'together', '.', 'although', 'there', 'was', 'a', 'lot', 'of', 'people', '_', 'com', '##ma', '_', 'we', 'felt', 'like', 'the', 'only', 'people', 'in', 'the', 'world', '.']\n",
            "Token IDs:  [1045, 3342, 2183, 2000, 1996, 16080, 2007, 2026, 2190, 2767, 1012, 2045, 2001, 1037, 2843, 1997, 2111, 1035, 4012, 2863, 1035, 2021, 2009, 2069, 2371, 2066, 2149, 1999, 1996, 2088, 1012, 1045, 3342, 2183, 2000, 2156, 1996, 16080, 2007, 2026, 2190, 2767, 1012, 2009, 2001, 1996, 2034, 2051, 2057, 2412, 2985, 2051, 2894, 2362, 1012, 2348, 2045, 2001, 1037, 2843, 1997, 2111, 1035, 4012, 2863, 1035, 2057, 2371, 2066, 1996, 2069, 2111, 1999, 1996, 2088, 1012]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v8u4w8GOEOvc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "6996aba8-1653-42e2-928f-69b79cb37318"
      },
      "source": [
        "longer_list = []\n",
        "for index, sent in enumerate(sentences_train):\n",
        "  if len(tokenizer.encode(sent, add_special_tokens=True)) > 500:\n",
        "    longer_list.append(index)\n",
        "sentences_train = np.delete(sentences_train, longer_list)\n",
        "labels_train = np.delete(labels_train, longer_list)\n",
        "\n",
        "max_len = 0\n",
        "# For every sentence...\n",
        "for sent in sentences_train:\n",
        "\n",
        "    # Tokenize the text and add `[CLS]` and `[SEP]` tokens.\n",
        "    input_ids = tokenizer.encode(sent, add_special_tokens=True)\n",
        "\n",
        "    # Update the maximum sentence length.\n",
        "    max_len = max(max_len, len(input_ids))\n",
        "\n",
        "print('Max train sentence length: ', max_len)\n",
        "\n",
        "max_len = 0\n",
        "# For every sentence...\n",
        "for sent in sentences_valid:\n",
        "\n",
        "    # Tokenize the text and add `[CLS]` and `[SEP]` tokens.\n",
        "    input_ids = tokenizer.encode(sent, add_special_tokens=True)\n",
        "\n",
        "    # Update the maximum sentence length.\n",
        "    max_len = max(max_len, len(input_ids))\n",
        "\n",
        "print('Max valid sentence length: ', max_len)\n",
        "\n",
        "max_len = 0\n",
        "# For every sentence...\n",
        "for sent in sentences_test:\n",
        "    try:\n",
        "      # Tokenize the text and add `[CLS]` and `[SEP]` tokens.\n",
        "      input_ids = tokenizer.encode(sent, add_special_tokens=True)\n",
        "    except:\n",
        "      print(sent)\n",
        "\n",
        "    # Update the maximum sentence length.\n",
        "    max_len = max(max_len, len(input_ids))\n",
        "\n",
        "print('Max test sentence length: ', max_len)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Max train sentence length:  242\n",
            "Max valid sentence length:  247\n",
            "Max test sentence length:  276\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YNOQzz-AEfQq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tokenize(sentences, labels):\n",
        "  # Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "  input_ids = []\n",
        "  attention_masks = []\n",
        "\n",
        "  # For every sentence...\n",
        "  for sent in sentences:\n",
        "      # `encode_plus` will:\n",
        "      #   (1) Tokenize the sentence.\n",
        "      #   (2) Prepend the `[CLS]` token to the start.\n",
        "      #   (3) Append the `[SEP]` token to the end.\n",
        "      #   (4) Map tokens to their IDs.\n",
        "      #   (5) Pad or truncate the sentence to `max_length`\n",
        "      #   (6) Create attention masks for [PAD] tokens.\n",
        "\n",
        "      encoded_dict = tokenizer.encode_plus(\n",
        "                          sent,                      # Sentence to encode.\n",
        "                          add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                          max_length = 256,           # Pad & truncate all sentences.\n",
        "                          pad_to_max_length = True,\n",
        "                          return_attention_mask = True,   # Construct attn. masks.\n",
        "                          return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                    )\n",
        "      \n",
        "      # Add the encoded sentence to the list.    \n",
        "      input_ids.append(encoded_dict['input_ids'])\n",
        "      \n",
        "      # And its attention mask (simply differentiates padding from non-padding).\n",
        "      attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "  # Convert the lists into tensors.\n",
        "  input_ids = torch.cat(input_ids, dim=0)\n",
        "  attention_masks = torch.cat(attention_masks, dim=0)\n",
        "  labels = torch.from_numpy(labels)\n",
        "\n",
        "  # Print sentence 0, now as a list of IDs.\n",
        "  print('Original: ', sentences[0])\n",
        "  print('Token IDs:', input_ids[0])\n",
        "  return(input_ids, attention_masks, labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rxlIQmj2EgTC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}