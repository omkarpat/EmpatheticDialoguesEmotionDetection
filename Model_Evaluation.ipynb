{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Model Evaluation.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyM6O6VUhzosYG16kWwxzDhe",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f4874d73664e471290ab0e583771bf0b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_40e9b0bb00c640138d550a64a8fb9ea6",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_379ea2960c43419c960715c9b8d07df2",
              "IPY_MODEL_b01ae50f4bc84e79aa1da055905f34fa"
            ]
          }
        },
        "40e9b0bb00c640138d550a64a8fb9ea6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "379ea2960c43419c960715c9b8d07df2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_d180b1e73647474bbc0e522860d103f4",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_54dde672043141cc90d148225f9b0f25"
          }
        },
        "b01ae50f4bc84e79aa1da055905f34fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_8105b9299e114eb7911e4f02dbc27ceb",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 232k/232k [00:00&lt;00:00, 546kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_33e231d1b88a492ab089624402e2c868"
          }
        },
        "d180b1e73647474bbc0e522860d103f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "54dde672043141cc90d148225f9b0f25": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8105b9299e114eb7911e4f02dbc27ceb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "33e231d1b88a492ab089624402e2c868": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/omkarpat/EmpatheticDialoguesEmotionDetection/blob/master/Model_Evaluation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mKC2EjlunupU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "outputId": "93c07f00-e27d-4ab7-bac7-13cec634e4fd"
      },
      "source": [
        "# Colab settings/mount\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "%cd gdrive/My\\ Drive/CSE\\ 245\\ Project"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n",
            "/content/gdrive/My Drive/CSE 245 Project\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s3dPyPP9n9Gg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 621
        },
        "outputId": "5bb45163-797a-45b0-d07e-447fd5ee220b"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/27/3c/91ed8f5c4e7ef3227b4119200fc0ed4b4fd965b1f0172021c25701087825/transformers-3.0.2-py3-none-any.whl (769kB)\n",
            "\r\u001b[K     |▍                               | 10kB 25.7MB/s eta 0:00:01\r\u001b[K     |▉                               | 20kB 5.8MB/s eta 0:00:01\r\u001b[K     |█▎                              | 30kB 7.3MB/s eta 0:00:01\r\u001b[K     |█▊                              | 40kB 8.1MB/s eta 0:00:01\r\u001b[K     |██▏                             | 51kB 6.9MB/s eta 0:00:01\r\u001b[K     |██▋                             | 61kB 7.9MB/s eta 0:00:01\r\u001b[K     |███                             | 71kB 7.8MB/s eta 0:00:01\r\u001b[K     |███▍                            | 81kB 8.5MB/s eta 0:00:01\r\u001b[K     |███▉                            | 92kB 8.7MB/s eta 0:00:01\r\u001b[K     |████▎                           | 102kB 9.1MB/s eta 0:00:01\r\u001b[K     |████▊                           | 112kB 9.1MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 122kB 9.1MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 133kB 9.1MB/s eta 0:00:01\r\u001b[K     |██████                          | 143kB 9.1MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 153kB 9.1MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 163kB 9.1MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 174kB 9.1MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 184kB 9.1MB/s eta 0:00:01\r\u001b[K     |████████                        | 194kB 9.1MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 204kB 9.1MB/s eta 0:00:01\r\u001b[K     |█████████                       | 215kB 9.1MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 225kB 9.1MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 235kB 9.1MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 245kB 9.1MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 256kB 9.1MB/s eta 0:00:01\r\u001b[K     |███████████                     | 266kB 9.1MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 276kB 9.1MB/s eta 0:00:01\r\u001b[K     |████████████                    | 286kB 9.1MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 296kB 9.1MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 307kB 9.1MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 317kB 9.1MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 327kB 9.1MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 337kB 9.1MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 348kB 9.1MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 358kB 9.1MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 368kB 9.1MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 378kB 9.1MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 389kB 9.1MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 399kB 9.1MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 409kB 9.1MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 419kB 9.1MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 430kB 9.1MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 440kB 9.1MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 450kB 9.1MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 460kB 9.1MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 471kB 9.1MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 481kB 9.1MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 491kB 9.1MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 501kB 9.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 512kB 9.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 522kB 9.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 532kB 9.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 542kB 9.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 552kB 9.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 563kB 9.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 573kB 9.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 583kB 9.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 593kB 9.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 604kB 9.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 614kB 9.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 624kB 9.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 634kB 9.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 645kB 9.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 655kB 9.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 665kB 9.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 675kB 9.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 686kB 9.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 696kB 9.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 706kB 9.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 716kB 9.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 727kB 9.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 737kB 9.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 747kB 9.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 757kB 9.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 768kB 9.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 778kB 9.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Collecting tokenizers==0.8.1.rc1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/40/d0/30d5f8d221a0ed981a186c8eb986ce1c94e3a6e87f994eae9f4aa5250217/tokenizers-0.8.1rc1-cp36-cp36m-manylinux1_x86_64.whl (3.0MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0MB 44.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Collecting sentencepiece!=0.1.92\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 40.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 58.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.9)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (1.12.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.15.1)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893260 sha256=30c09fb349f383c4355f439e82fd64e378ac497eca475133f0585868ecefa8de\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: tokenizers, sentencepiece, sacremoses, transformers\n",
            "Successfully installed sacremoses-0.0.43 sentencepiece-0.1.91 tokenizers-0.8.1rc1 transformers-3.0.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0pICnJ8zoBqf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "outputId": "c01c6877-0544-4581-fcf5-dfa400d7eae1"
      },
      "source": [
        "!ls"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " basic_collapsed_emotion_model2_save\n",
            " basic_collapsed_emotion_model4_save\n",
            " collapsing_categories.txt\n",
            " Data\n",
            "'Emotion Detection.gslides'\n",
            " emotion_model1_save\n",
            " emotion_model2_save\n",
            " emotion_model3_save\n",
            " emotion_model4_save\n",
            "'Final PPT.gslides'\n",
            " less_restrictive_collapsed_emotion_model2_save\n",
            " less_restrictive_collapsed_emotion_model4_save\n",
            " model4_more_restrictive_collapsed_emotion_save\n",
            " more_restrictive_collapsed_emotion_model2_save\n",
            " more_restrictive_collapsed_emotion_model4_save\n",
            " pos_neg_model1_save\n",
            " pos_neg_model2_save\n",
            " pos_neg_model3_save\n",
            " pos_neg_model4_save\n",
            " valence_model1_save\n",
            " valence_model2_save\n",
            " valence_model3_save\n",
            " valence_model4_save\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "seESJAXDoHSP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 816
        },
        "outputId": "a0ab4fd8-d1b4-4b1b-a90c-e8b54aa29749"
      },
      "source": [
        "!ls Data"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "'Data Exploration.ipynb'\n",
            " data_fixed_train_complement_analysis.csv\n",
            " data_fixed_train.json\n",
            " data_sample_100.json\n",
            " data_sample_10_complement_analysis.csv\n",
            " data_sample_10.json\n",
            " data_sample_10_processed.json\n",
            " data_sample_fixed_processed_final.json\n",
            " data_sample_fixed_processed_model1_final.csv\n",
            " data_sample_fixed_processed_model2_final.csv\n",
            " data_sample_fixed_processed_model3_final.csv\n",
            " data_sample_fixed_processed_model4_final.csv\n",
            " fixed\n",
            " fixed_test.csv\n",
            " fixed_test.json\n",
            " fixed_train_516.csv\n",
            " fixed_valid.csv\n",
            " fixed_valid.json\n",
            "'informative words.ipynb'\n",
            " model1_predictions_test.csv\n",
            " model1_predictions_train.csv\n",
            " model1_predictions_valid.csv\n",
            " model2_predictions_test.csv\n",
            " model2_predictions_train.csv\n",
            " model2_predictions_valid.csv\n",
            " model3_predictions_test.csv\n",
            " model3_predictions_train.csv\n",
            " model3_predictions_valid.csv\n",
            " model4_predictions_test.csv\n",
            " model4_predictions_train.csv\n",
            " model4_predictions_valid.csv\n",
            "'Model Metrics.gsheet'\n",
            " Raw\n",
            " test_fixed_processed_final.json\n",
            " test_fixed_processed_model1_final.csv\n",
            " test_fixed_processed_model2_final.csv\n",
            " test_fixed_processed_model3_final.csv\n",
            " test_fixed_processed_model4_final.csv\n",
            " valence_groupings.txt\n",
            " valid.csv\n",
            " valid_fixed_processed_final.json\n",
            " valid_fixed_processed_model1_final.csv\n",
            " valid_fixed_processed_model2_final.csv\n",
            " valid_fixed_processed_model3_final.csv\n",
            " valid_fixed_processed_model4_final.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F0cbKcO1oKfG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset_name = \"model4\"\n",
        "model_name = \"model4\"\n",
        "model_type = \"more_restrictive_collapsed_emotion\" #pos_neg | emotion | valence | basic_collapsed_emotion | more_restrictive_collapsed_emotion | less_restrictive_collapsed_emotion"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vqAW4wudoxTL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "db0b7325-5dd0-4055-8e55-dceafd9d24af"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Get the GPU device name.\n",
        "device_name = tf.test.gpu_device_name()\n",
        "\n",
        "# The device name should look like the following:\n",
        "if device_name == '/device:GPU:0':\n",
        "    print('Found GPU at: {}'.format(device_name))\n",
        "else:\n",
        "    raise SystemError('GPU device not found')\n",
        "\n",
        "import torch\n",
        "\n",
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():    \n",
        "\n",
        "    # Tell PyTorch to use the GPU.    \n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n",
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla P100-PCIE-16GB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q6fkdwMwpI5h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "train_filename = \"Data/data_sample_fixed_processed_\" + dataset_name + \"_final.csv\"\n",
        "valid_filename = \"Data/valid_fixed_processed_\" + dataset_name + \"_final.csv\"\n",
        "test_filename = \"Data/test_fixed_processed_\" + dataset_name + \"_final.csv\"\n",
        "\n",
        "train_df = pd.read_csv(train_filename, sep='|', error_bad_lines=False)\n",
        "train_df = train_df.dropna()\n",
        "valid_df = pd.read_csv(valid_filename, sep='|', error_bad_lines=False)\n",
        "valid_df = valid_df.dropna()\n",
        "test_df = pd.read_csv(test_filename, sep='|', error_bad_lines=False)\n",
        "test_df = test_df.dropna()"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ifj5qHOPqKNL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f34d9073-8204-4e36-b2d4-8d27e3bdb6ec"
      },
      "source": [
        "category2index_more_restrictive_model2 = {\n",
        "    \"guilty\":0,\n",
        "    \"ashamed\":0,\n",
        "    \"furious\":1,\n",
        "    \"angry\":1,\n",
        "    \"terrified\":2,\n",
        "    \"afraid\":2,\n",
        "    \"sentimental\":3,\n",
        "    \"sad\":4,\n",
        "    \"hopeful\":5,\n",
        "    \"joyful\":6,\n",
        "    \"impressed\":7,\n",
        "    \"proud\":8,\n",
        "    \"grateful\":9,\n",
        "    \"lonely\":10,\n",
        "    \"surprised\":11,\n",
        "    \"anxious\":12,\n",
        "    \"trusting\":13,\n",
        "    \"nostalgic\":14,\n",
        "    \"excited\":15,\n",
        "    \"disgusted\":16,\n",
        "    \"caring\":17,\n",
        "    \"prepared\":18,\n",
        "    \"disappointed\":19,\n",
        "    \"faithful\":20,\n",
        "    \"confident\":21,\n",
        "    \"apprehensive\":22,\n",
        "    \"jealous\":23,\n",
        "    \"embarrassed\":24,\n",
        "    \"devastated\":25,\n",
        "    \"annoyed\":26,\n",
        "    \"content\":27,\n",
        "    \"anticipating\":28\n",
        "}\n",
        "\n",
        "category2index_more_restrictive_model4 = {\n",
        "    \"guilty\":0,\n",
        "    \"ashamed\":0,\n",
        "    \"furious\":1,\n",
        "    \"angry\":1,\n",
        "    \"terrified\":2,\n",
        "    \"afraid\":2,\n",
        "    \"nostalgic\":3,\n",
        "    \"sentimental\":3,\n",
        "    \"sad\":4,\n",
        "    \"hopeful\":5,\n",
        "    \"joyful\":6,\n",
        "    \"impressed\":7,\n",
        "    \"proud\":8,\n",
        "    \"grateful\":9,\n",
        "    \"lonely\":10,\n",
        "    \"surprised\":11,\n",
        "    \"anxious\":12,\n",
        "    \"trusting\":13,\n",
        "    \"excited\":14,\n",
        "    \"disgusted\":15,\n",
        "    \"caring\":16,\n",
        "    \"prepared\":17,\n",
        "    \"disappointed\":18,\n",
        "    \"faithful\":19,\n",
        "    \"confident\":20,\n",
        "    \"apprehensive\":21,\n",
        "    \"jealous\":22,\n",
        "    \"embarrassed\":23,\n",
        "    \"devastated\":24,\n",
        "    \"annoyed\":25,\n",
        "    \"content\":26,\n",
        "    \"anticipating\":27\n",
        "}\n",
        "\n",
        "category2index_less_restrictive_model2 = {\n",
        "    \"guilty\":0,\n",
        "    \"ashamed\":0,\n",
        "    \"furious\":1,\n",
        "    \"angry\":1,\n",
        "    \"terrified\":2,\n",
        "    \"afraid\":2,\n",
        "    \"nostalgic\":3,\n",
        "    \"sentimental\":3,\n",
        "    \"anxious\":4,\n",
        "    \"apprehensive\":4,\n",
        "    \"excited\":5,\n",
        "    \"anticipating\":5,\n",
        "    \"sad\":6,\n",
        "    \"hopeful\":7,\n",
        "    \"joyful\":8,\n",
        "    \"impressed\":9,\n",
        "    \"proud\":10,\n",
        "    \"grateful\":11,\n",
        "    \"lonely\":12,\n",
        "    \"surprised\":13,\n",
        "    \"trusting\":14,\n",
        "    \"disgusted\":15,\n",
        "    \"caring\":16,\n",
        "    \"prepared\":17,\n",
        "    \"disappointed\":18,\n",
        "    \"faithful\":19,\n",
        "    \"confident\":20,\n",
        "    \"jealous\":21,\n",
        "    \"embarrassed\":22,\n",
        "    \"devastated\":23,\n",
        "    \"annoyed\":24,\n",
        "    \"content\":25    \n",
        "}\n",
        "\n",
        "category2index_less_restrictive_model4 = {\n",
        "    \"guilty\":0,\n",
        "    \"ashamed\":0,\n",
        "    \"furious\":1,\n",
        "    \"angry\":1,\n",
        "    \"terrified\":2,\n",
        "    \"afraid\":2,\n",
        "    \"nostalgic\":3,\n",
        "    \"sentimental\":3,\n",
        "    \"anxious\":4,\n",
        "    \"apprehensive\":4,\n",
        "    \"excited\":5,\n",
        "    \"joyful\":5,\n",
        "    \"anticipating\":6,\n",
        "    \"sad\":7,\n",
        "    \"hopeful\":8,\n",
        "    \"impressed\":9,\n",
        "    \"proud\":10,\n",
        "    \"grateful\":11,\n",
        "    \"lonely\":12,\n",
        "    \"surprised\":13,\n",
        "    \"trusting\":14,\n",
        "    \"disgusted\":15,\n",
        "    \"caring\":16,\n",
        "    \"prepared\":17,\n",
        "    \"disappointed\":18,\n",
        "    \"faithful\":19,\n",
        "    \"confident\":20,\n",
        "    \"jealous\":21,\n",
        "    \"embarrassed\":22,\n",
        "    \"devastated\":23,\n",
        "    \"annoyed\":24,\n",
        "    \"content\":25    \n",
        "}\n",
        "\n",
        "category2index_basic_collapsed_emotion = {\n",
        "    \"nostalgic\":1,\n",
        "    \"sentimental\":1,\n",
        "    \"sad\":2,\n",
        "    \"devastated\":2,\n",
        "    \"hopeful\":3,\n",
        "    \"joyful\":4,\n",
        "    \"impressed\":5,\n",
        "    \"terrified\":6,\n",
        "    \"afraid\":6,\n",
        "    \"proud\":7,\n",
        "    \"grateful\":8,\n",
        "    \"lonely\":9,\n",
        "    \"surprised\":10,\n",
        "    \"anxious\":11,\n",
        "    \"guilty\":12,\n",
        "    \"trusting\":13,\n",
        "    \"excited\":15,\n",
        "    \"disgusted\":16,\n",
        "    \"caring\":17,\n",
        "    \"furious\":18,\n",
        "    \"angry\":18,\n",
        "    \"prepared\":19,\n",
        "    \"disappointed\":20,\n",
        "    \"faithful\":21,\n",
        "    \"confident\":22,\n",
        "    \"apprehensive\":23,\n",
        "    \"jealous\":24,\n",
        "    \"embarrassed\":25,\n",
        "    \"annoyed\":26,\n",
        "    \"ashamed\":27,\n",
        "    \"content\":28,\n",
        "    \"anticipating\":29\n",
        "}\n",
        "\n",
        "category2index = {\n",
        "    \"invalid\":0,\n",
        "    \"sentimental\":1,\n",
        "    \"sad\":2,\n",
        "    \"hopeful\":3,\n",
        "    \"joyful\":4,\n",
        "    \"impressed\":5,\n",
        "    \"terrified\":6,\n",
        "    \"proud\":7,\n",
        "    \"afraid\":8,\n",
        "    \"grateful\":9,\n",
        "    \"lonely\":10,\n",
        "    \"surprised\":11,\n",
        "    \"anxious\":12,\n",
        "    \"guilty\":13,\n",
        "    \"trusting\":14,\n",
        "    \"nostalgic\":15,\n",
        "    \"excited\":16,\n",
        "    \"disgusted\":17,\n",
        "    \"caring\":18,\n",
        "    \"furious\":19,\n",
        "    \"angry\":20,\n",
        "    \"prepared\":21,\n",
        "    \"disappointed\":22,\n",
        "    \"faithful\":23,\n",
        "    \"confident\":24,\n",
        "    \"apprehensive\":25,\n",
        "    \"jealous\":26,\n",
        "    \"embarrassed\":27,\n",
        "    \"devastated\":28,\n",
        "    \"annoyed\":29,\n",
        "    \"ashamed\":30,\n",
        "    \"content\":31,\n",
        "    \"anticipating\":32\n",
        "}\n",
        "\n",
        "if model_name == \"model2\":\n",
        "  if model_type == \"more_restrictive_collapsed_emotion\":\n",
        "    category2index = category2index_more_restrictive_model2\n",
        "  elif model_type == \"less_restrictive_collapsed_emotion\":\n",
        "    category2index = category2index_less_restrictive_model2\n",
        "if model_name == \"model4\":\n",
        "  if model_type == \"more_restrictive_collapsed_emotion\":\n",
        "    category2index = category2index_more_restrictive_model4\n",
        "  elif model_type == \"less_restrictive_collapsed_emotion\":\n",
        "    category2index = category2index_less_restrictive_model4\n",
        "if model_type == \"basic_collapsed_emotion\":\n",
        "  category2index = category2index_basic_collapsed_emotion\n",
        "\n",
        "number_of_labels = len(set(category2index.values()))\n",
        "#print(category2index)\n",
        "print(\"Preparing data for training %s, with %s. Total Classes: %s\" % (model_name, model_type, number_of_labels))\n",
        "\n",
        "index2category = {}\n",
        "for key, value in category2index.items():\n",
        "  index2category[value] = key\n",
        "\n",
        "def category2label(category):\n",
        "  for key in category2index.keys():\n",
        "    if key == category:\n",
        "      return category2index[key]\n",
        "  return 0\n",
        "\n",
        "def label2emotion(labels):\n",
        "  emotion_list = []\n",
        "  for label in labels:\n",
        "    emotion_list.append(index2category[label])\n",
        "  return emotion_list\n",
        "\n",
        "def label2category(labels):\n",
        "  emotion_list = []\n",
        "  for label in labels:\n",
        "    if label == 0:\n",
        "      emotion_list.append(\"negative\")\n",
        "    else:\n",
        "      emotion_list.append(\"positive\")\n",
        "  return emotion_list"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Preparing data for training model4, with more_restrictive_collapsed_emotion. Total Classes: 28\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qC7JGNlyqQxv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 454
        },
        "outputId": "4f61d11a-833b-4514-bc9d-aae1007522d7"
      },
      "source": [
        "print('Number of training sentences: {:,}\\n'.format(train_df.shape[0]))\n",
        "print('Number of valid sentences: {:,}\\n'.format(valid_df.shape[0]))\n",
        "print('Number of test sentences: {:,}\\n'.format(test_df.shape[0]))\n",
        "\n",
        "if \"emotion\" in model_type:\n",
        "  train_df['label'] = train_df['emotion'].apply(lambda x: int(category2label(x.lower())))\n",
        "  valid_df['label'] = valid_df['emotion'].apply(lambda x: int(category2label(x.lower())))\n",
        "  test_df['label'] = test_df['emotion'].apply(lambda x: int(category2label(x.lower())))\n",
        "else:\n",
        "  train_df['label'] = train_df['processed_emotion'].apply(lambda x: 0 if x == \"negative\" else 1)\n",
        "  valid_df['label'] = valid_df['processed_emotion'].apply(lambda x: 0 if x == \"negative\" else 1)\n",
        "  test_df['label'] = test_df['processed_emotion'].apply(lambda x: 0 if x == \"negative\" else 1)\n",
        "\n",
        "# Display 10 random rows from the data.\n",
        "train_df.sample(10)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training sentences: 19,533\n",
            "\n",
            "Number of valid sentences: 2,758\n",
            "\n",
            "Number of test sentences: 2,538\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>emotion</th>\n",
              "      <th>processed_emotion</th>\n",
              "      <th>text</th>\n",
              "      <th>vader_neg</th>\n",
              "      <th>vader_neu</th>\n",
              "      <th>vader_pos</th>\n",
              "      <th>vader_compound</th>\n",
              "      <th>textblob</th>\n",
              "      <th>flair_value</th>\n",
              "      <th>flair_confidence</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>4150</th>\n",
              "      <td>joyful</td>\n",
              "      <td>positive</td>\n",
              "      <td>I could ask for a better wife! My wife is my s...</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.699</td>\n",
              "      <td>0.301</td>\n",
              "      <td>0.9467</td>\n",
              "      <td>0.321364</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>0.999958</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3273</th>\n",
              "      <td>anticipating</td>\n",
              "      <td>positive</td>\n",
              "      <td>I am really excited for the new super smash br...</td>\n",
              "      <td>0.026</td>\n",
              "      <td>0.619</td>\n",
              "      <td>0.355</td>\n",
              "      <td>0.9764</td>\n",
              "      <td>0.115960</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>0.999962</td>\n",
              "      <td>27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4719</th>\n",
              "      <td>proud</td>\n",
              "      <td>positive</td>\n",
              "      <td>Managed to get a huge bonus for hard work. So ...</td>\n",
              "      <td>0.034</td>\n",
              "      <td>0.745</td>\n",
              "      <td>0.221</td>\n",
              "      <td>0.9601</td>\n",
              "      <td>0.143434</td>\n",
              "      <td>NEGATIVE</td>\n",
              "      <td>0.649291</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17263</th>\n",
              "      <td>caring</td>\n",
              "      <td>positive</td>\n",
              "      <td>I felt like sharing a story about last week fo...</td>\n",
              "      <td>0.017</td>\n",
              "      <td>0.727</td>\n",
              "      <td>0.256</td>\n",
              "      <td>0.9751</td>\n",
              "      <td>0.375000</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>0.938712</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8513</th>\n",
              "      <td>surprised</td>\n",
              "      <td>positive</td>\n",
              "      <td>I was at a local restaurant that my wife reall...</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.730</td>\n",
              "      <td>0.270</td>\n",
              "      <td>0.9790</td>\n",
              "      <td>0.212821</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>0.999456</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7264</th>\n",
              "      <td>surprised</td>\n",
              "      <td>positive</td>\n",
              "      <td>I got a letter in the mail. Apparently a dista...</td>\n",
              "      <td>0.078</td>\n",
              "      <td>0.676</td>\n",
              "      <td>0.246</td>\n",
              "      <td>0.9345</td>\n",
              "      <td>0.121429</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>0.987066</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2548</th>\n",
              "      <td>sentimental</td>\n",
              "      <td>positive</td>\n",
              "      <td>I love watching the movies I watched as a kid ...</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.584</td>\n",
              "      <td>0.416</td>\n",
              "      <td>0.9744</td>\n",
              "      <td>0.441667</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>0.999461</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4993</th>\n",
              "      <td>excited</td>\n",
              "      <td>positive</td>\n",
              "      <td>I signed up for a cruise! I haven't been on on...</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.773</td>\n",
              "      <td>0.227</td>\n",
              "      <td>0.9588</td>\n",
              "      <td>0.493125</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>0.996583</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11491</th>\n",
              "      <td>angry</td>\n",
              "      <td>negative</td>\n",
              "      <td>I am so pissed of at President Trump I am so p...</td>\n",
              "      <td>0.249</td>\n",
              "      <td>0.639</td>\n",
              "      <td>0.112</td>\n",
              "      <td>-0.8360</td>\n",
              "      <td>0.175000</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>0.943997</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5150</th>\n",
              "      <td>anticipating</td>\n",
              "      <td>positive</td>\n",
              "      <td>I'm going on a date this weekend. I'm pretty a...</td>\n",
              "      <td>0.076</td>\n",
              "      <td>0.640</td>\n",
              "      <td>0.284</td>\n",
              "      <td>0.9313</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>0.999694</td>\n",
              "      <td>27</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            emotion processed_emotion  ... flair_confidence  label\n",
              "4150         joyful          positive  ...         0.999958      6\n",
              "3273   anticipating          positive  ...         0.999962     27\n",
              "4719          proud          positive  ...         0.649291      8\n",
              "17263        caring          positive  ...         0.938712     16\n",
              "8513      surprised          positive  ...         0.999456     11\n",
              "7264      surprised          positive  ...         0.987066     11\n",
              "2548    sentimental          positive  ...         0.999461      3\n",
              "4993        excited          positive  ...         0.996583     14\n",
              "11491         angry          negative  ...         0.943997      1\n",
              "5150   anticipating          positive  ...         0.999694     27\n",
              "\n",
              "[10 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xkof-2Vf8ktk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def compute_category(value):\n",
        "  if value == 0:\n",
        "    return \"neutral\"\n",
        "  elif float(value) < 0:\n",
        "    return \"negative\"\n",
        "  else:\n",
        "    return \"positive\""
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vgq5lmpK7Mmc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 640
        },
        "outputId": "8bd3e604-52c7-42d0-cb73-afc74a6caead"
      },
      "source": [
        "train_df['flair_value'] = train_df['flair_value'].apply(lambda x: x.lower())\n",
        "valid_df['flair_value'] = valid_df['flair_value'].apply(lambda x: x.lower())\n",
        "test_df['flair_value'] = test_df['flair_value'].apply(lambda x: x.lower())\n",
        "train_df['textblob_category'] = train_df['textblob'].apply(lambda x: compute_category(x))\n",
        "valid_df['textblob_category'] = valid_df['textblob'].apply(lambda x: compute_category(x))\n",
        "test_df['textblob_category'] = test_df['textblob'].apply(lambda x: compute_category(x))\n",
        "train_df['vader_category'] = train_df['vader_compound'].apply(lambda x: compute_category(x))\n",
        "valid_df['vader_category'] = valid_df['vader_compound'].apply(lambda x: compute_category(x))\n",
        "test_df['vader_category'] = test_df['vader_compound'].apply(lambda x: compute_category(x))\n",
        "train_df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>emotion</th>\n",
              "      <th>processed_emotion</th>\n",
              "      <th>text</th>\n",
              "      <th>vader_neg</th>\n",
              "      <th>vader_neu</th>\n",
              "      <th>vader_pos</th>\n",
              "      <th>vader_compound</th>\n",
              "      <th>textblob</th>\n",
              "      <th>flair_value</th>\n",
              "      <th>flair_confidence</th>\n",
              "      <th>textblob_category</th>\n",
              "      <th>vader_category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>sentimental</td>\n",
              "      <td>positive</td>\n",
              "      <td>I remember going to the fireworks with my best...</td>\n",
              "      <td>0.075</td>\n",
              "      <td>0.600</td>\n",
              "      <td>0.325</td>\n",
              "      <td>0.9803</td>\n",
              "      <td>0.450000</td>\n",
              "      <td>positive</td>\n",
              "      <td>0.995377</td>\n",
              "      <td>positive</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>sad</td>\n",
              "      <td>negative</td>\n",
              "      <td>One year during christmas_comma_ i did not get...</td>\n",
              "      <td>0.193</td>\n",
              "      <td>0.752</td>\n",
              "      <td>0.054</td>\n",
              "      <td>-0.8626</td>\n",
              "      <td>-0.134286</td>\n",
              "      <td>positive</td>\n",
              "      <td>0.574868</td>\n",
              "      <td>negative</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>hopeful</td>\n",
              "      <td>positive</td>\n",
              "      <td>I have been in college for four years and am o...</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.937</td>\n",
              "      <td>0.063</td>\n",
              "      <td>0.3612</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>positive</td>\n",
              "      <td>0.988017</td>\n",
              "      <td>neutral</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>joyful</td>\n",
              "      <td>positive</td>\n",
              "      <td>You never know how happy you can be until you ...</td>\n",
              "      <td>0.195</td>\n",
              "      <td>0.633</td>\n",
              "      <td>0.172</td>\n",
              "      <td>-0.0096</td>\n",
              "      <td>0.480000</td>\n",
              "      <td>positive</td>\n",
              "      <td>0.935849</td>\n",
              "      <td>positive</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>impressed</td>\n",
              "      <td>positive</td>\n",
              "      <td>the redsox have a chance to break the amount o...</td>\n",
              "      <td>0.054</td>\n",
              "      <td>0.702</td>\n",
              "      <td>0.244</td>\n",
              "      <td>0.8588</td>\n",
              "      <td>-0.093750</td>\n",
              "      <td>positive</td>\n",
              "      <td>0.998813</td>\n",
              "      <td>negative</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19528</th>\n",
              "      <td>afraid</td>\n",
              "      <td>negative</td>\n",
              "      <td>living out in the country when it gets dark it...</td>\n",
              "      <td>0.056</td>\n",
              "      <td>0.944</td>\n",
              "      <td>0.000</td>\n",
              "      <td>-0.3369</td>\n",
              "      <td>-0.147222</td>\n",
              "      <td>positive</td>\n",
              "      <td>0.891851</td>\n",
              "      <td>negative</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19529</th>\n",
              "      <td>trusting</td>\n",
              "      <td>positive</td>\n",
              "      <td>I took my boots off after a long day of workin...</td>\n",
              "      <td>0.059</td>\n",
              "      <td>0.941</td>\n",
              "      <td>0.000</td>\n",
              "      <td>-0.6083</td>\n",
              "      <td>-0.016667</td>\n",
              "      <td>negative</td>\n",
              "      <td>0.999897</td>\n",
              "      <td>negative</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19530</th>\n",
              "      <td>nostalgic</td>\n",
              "      <td>positive</td>\n",
              "      <td>Anytime I see a mall_comma_ I get nostalgic ab...</td>\n",
              "      <td>0.101</td>\n",
              "      <td>0.710</td>\n",
              "      <td>0.189</td>\n",
              "      <td>0.7263</td>\n",
              "      <td>-0.215000</td>\n",
              "      <td>positive</td>\n",
              "      <td>0.994397</td>\n",
              "      <td>negative</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19531</th>\n",
              "      <td>anticipating</td>\n",
              "      <td>positive</td>\n",
              "      <td>i cant wait to play the new madden_comma_ ive ...</td>\n",
              "      <td>0.050</td>\n",
              "      <td>0.737</td>\n",
              "      <td>0.213</td>\n",
              "      <td>0.8251</td>\n",
              "      <td>0.354545</td>\n",
              "      <td>positive</td>\n",
              "      <td>0.998630</td>\n",
              "      <td>positive</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19532</th>\n",
              "      <td>faithful</td>\n",
              "      <td>positive</td>\n",
              "      <td>I'm faithful I'm going down the right career p...</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.901</td>\n",
              "      <td>0.099</td>\n",
              "      <td>0.5774</td>\n",
              "      <td>0.083617</td>\n",
              "      <td>positive</td>\n",
              "      <td>0.997885</td>\n",
              "      <td>positive</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>19533 rows × 12 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            emotion processed_emotion  ... textblob_category  vader_category\n",
              "0       sentimental          positive  ...          positive        positive\n",
              "1               sad          negative  ...          negative        negative\n",
              "2           hopeful          positive  ...           neutral        positive\n",
              "3            joyful          positive  ...          positive        negative\n",
              "4         impressed          positive  ...          negative        positive\n",
              "...             ...               ...  ...               ...             ...\n",
              "19528        afraid          negative  ...          negative        negative\n",
              "19529      trusting          positive  ...          negative        negative\n",
              "19530     nostalgic          positive  ...          negative        positive\n",
              "19531  anticipating          positive  ...          positive        positive\n",
              "19532      faithful          positive  ...          positive        positive\n",
              "\n",
              "[19533 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "71LD7Abg-Oq3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "actual_labels_train = train_df.processed_emotion.values\n",
        "actual_labels_valid = valid_df.processed_emotion.values\n",
        "actual_labels_test = test_df.processed_emotion.values\n",
        "vader_labels_train = train_df.vader_category.values\n",
        "vader_labels_valid = valid_df.vader_category.values\n",
        "vader_labels_test = test_df.vader_category.values\n",
        "textblob_labels_train = train_df.textblob_category.values\n",
        "textblob_labels_valid = valid_df.textblob_category.values\n",
        "textblob_labels_test = test_df.textblob_category.values\n",
        "flair_labels_train = train_df.flair_value.values\n",
        "flair_labels_valid = valid_df.flair_value.values\n",
        "flair_labels_test = test_df.flair_value.values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i4aQtSUd-4_k",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7cb729c9-4c9c-42b2-c0bd-a355f48e6d02"
      },
      "source": [
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "print(\"Classwise Report for Vader\")\n",
        "print(\"Training set\")\n",
        "print(classification_report(actual_labels_train, vader_labels_train))\n",
        "print(\"Validation set\")\n",
        "print(classification_report(actual_labels_valid, vader_labels_valid))\n",
        "print(\"Testing set\")\n",
        "print(classification_report(actual_labels_test, vader_labels_test))\n",
        "\n",
        "print(\"Classwise Report for Textblob\")\n",
        "print(\"Training set\")\n",
        "print(classification_report(actual_labels_train, textblob_labels_train))\n",
        "print(\"Validation set\")\n",
        "print(classification_report(actual_labels_valid, textblob_labels_valid))\n",
        "print(\"Testing set\")\n",
        "print(classification_report(actual_labels_test, textblob_labels_test))\n",
        "\n",
        "print(\"Classwise Report for Flair\")\n",
        "print(\"Training set\")\n",
        "print(classification_report(actual_labels_train, flair_labels_train))\n",
        "print(\"Validation set\")\n",
        "print(classification_report(actual_labels_valid, flair_labels_valid))\n",
        "print(\"Testing set\")\n",
        "print(classification_report(actual_labels_test, flair_labels_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Classwise Report for Vader\n",
            "Training set\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.85      0.64      0.73      9673\n",
            "     neutral       0.00      0.00      0.00         0\n",
            "    positive       0.73      0.84      0.78      9860\n",
            "\n",
            "    accuracy                           0.74     19533\n",
            "   macro avg       0.52      0.49      0.50     19533\n",
            "weighted avg       0.79      0.74      0.75     19533\n",
            "\n",
            "Validation set\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.83      0.61      0.70      1374\n",
            "    positive       0.68      0.87      0.76      1299\n",
            "\n",
            "    accuracy                           0.74      2673\n",
            "   macro avg       0.75      0.74      0.73      2673\n",
            "weighted avg       0.76      0.74      0.73      2673\n",
            "\n",
            "Testing set\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.84      0.62      0.71      1225\n",
            "    positive       0.71      0.89      0.79      1313\n",
            "\n",
            "    accuracy                           0.76      2538\n",
            "   macro avg       0.78      0.75      0.75      2538\n",
            "weighted avg       0.77      0.76      0.75      2538\n",
            "\n",
            "Classwise Report for Textblob\n",
            "Training set\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.78      0.50      0.61      9673\n",
            "     neutral       0.00      0.00      0.00         0\n",
            "    positive       0.66      0.80      0.72      9860\n",
            "\n",
            "    accuracy                           0.65     19533\n",
            "   macro avg       0.48      0.43      0.45     19533\n",
            "weighted avg       0.72      0.65      0.67     19533\n",
            "\n",
            "Validation set\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.78      0.48      0.59      1374\n",
            "     neutral       0.00      0.00      0.00         0\n",
            "    positive       0.63      0.80      0.71      1299\n",
            "\n",
            "    accuracy                           0.64      2673\n",
            "   macro avg       0.47      0.43      0.43      2673\n",
            "weighted avg       0.71      0.64      0.65      2673\n",
            "\n",
            "Testing set\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.78      0.51      0.61      1225\n",
            "     neutral       0.00      0.00      0.00         0\n",
            "    positive       0.67      0.84      0.75      1313\n",
            "\n",
            "    accuracy                           0.68      2538\n",
            "   macro avg       0.48      0.45      0.45      2538\n",
            "weighted avg       0.72      0.68      0.68      2538\n",
            "\n",
            "Classwise Report for Flair\n",
            "Training set\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.64      0.62      0.63      9673\n",
            "    positive       0.64      0.66      0.65      9860\n",
            "\n",
            "    accuracy                           0.64     19533\n",
            "   macro avg       0.64      0.64      0.64     19533\n",
            "weighted avg       0.64      0.64      0.64     19533\n",
            "\n",
            "Validation set\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.79      0.78      0.78      1374\n",
            "    positive       0.77      0.78      0.77      1299\n",
            "\n",
            "    accuracy                           0.78      2673\n",
            "   macro avg       0.78      0.78      0.78      2673\n",
            "weighted avg       0.78      0.78      0.78      2673\n",
            "\n",
            "Testing set\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.64      0.62      0.63      1225\n",
            "    positive       0.66      0.68      0.67      1313\n",
            "\n",
            "    accuracy                           0.65      2538\n",
            "   macro avg       0.65      0.65      0.65      2538\n",
            "weighted avg       0.65      0.65      0.65      2538\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pPQeXgNmrpRa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentences_train = train_df.text.values\n",
        "labels_train = train_df.label.values\n",
        "sentences_valid = valid_df.text.values\n",
        "labels_valid = valid_df.label.values\n",
        "sentences_test = test_df.text.values\n",
        "labels_test = test_df.label.values"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Ixqmd-SsFNa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120,
          "referenced_widgets": [
            "f4874d73664e471290ab0e583771bf0b",
            "40e9b0bb00c640138d550a64a8fb9ea6",
            "379ea2960c43419c960715c9b8d07df2",
            "b01ae50f4bc84e79aa1da055905f34fa",
            "d180b1e73647474bbc0e522860d103f4",
            "54dde672043141cc90d148225f9b0f25",
            "8105b9299e114eb7911e4f02dbc27ceb",
            "33e231d1b88a492ab089624402e2c868"
          ]
        },
        "outputId": "c583a48e-1bc8-4e2b-e391-912b7fca76f0"
      },
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "# Load the BERT tokenizer.\n",
        "print('Loading BERT tokenizer...')\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
        "\n",
        "longer_list = []\n",
        "for index, sent in enumerate(sentences_train):\n",
        "  if len(tokenizer.encode(sent, add_special_tokens=True)) > 500:\n",
        "    longer_list.append(index)\n",
        "sentences_train = np.delete(sentences_train, longer_list)\n",
        "labels_train = np.delete(labels_train, longer_list)\n",
        "\n",
        "max_len = 0\n",
        "# For every sentence...\n",
        "for sent in sentences_train:\n",
        "\n",
        "    # Tokenize the text and add `[CLS]` and `[SEP]` tokens.\n",
        "    input_ids = tokenizer.encode(sent, add_special_tokens=True)\n",
        "\n",
        "    # Update the maximum sentence length.\n",
        "    max_len = max(max_len, len(input_ids))\n",
        "\n",
        "print('Max train sentence length: ', max_len)\n",
        "\n",
        "max_len = 0\n",
        "# For every sentence...\n",
        "for sent in sentences_valid:\n",
        "\n",
        "    # Tokenize the text and add `[CLS]` and `[SEP]` tokens.\n",
        "    input_ids = tokenizer.encode(sent, add_special_tokens=True)\n",
        "\n",
        "    # Update the maximum sentence length.\n",
        "    max_len = max(max_len, len(input_ids))\n",
        "\n",
        "print('Max valid sentence length: ', max_len)\n",
        "\n",
        "max_len = 0\n",
        "# For every sentence...\n",
        "for sent in sentences_test:\n",
        "    try:\n",
        "      # Tokenize the text and add `[CLS]` and `[SEP]` tokens.\n",
        "      input_ids = tokenizer.encode(sent, add_special_tokens=True)\n",
        "    except:\n",
        "      print(sent)\n",
        "\n",
        "    # Update the maximum sentence length.\n",
        "    max_len = max(max_len, len(input_ids))\n",
        "\n",
        "print('Max test sentence length: ', max_len)\n",
        "\n",
        "def tokenize(sentences, labels):\n",
        "  # Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "  input_ids = []\n",
        "  attention_masks = []\n",
        "\n",
        "  # For every sentence...\n",
        "  for sent in sentences:\n",
        "      # `encode_plus` will:\n",
        "      #   (1) Tokenize the sentence.\n",
        "      #   (2) Prepend the `[CLS]` token to the start.\n",
        "      #   (3) Append the `[SEP]` token to the end.\n",
        "      #   (4) Map tokens to their IDs.\n",
        "      #   (5) Pad or truncate the sentence to `max_length`\n",
        "      #   (6) Create attention masks for [PAD] tokens.\n",
        "\n",
        "      encoded_dict = tokenizer.encode_plus(\n",
        "                          sent,                      # Sentence to encode.\n",
        "                          add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                          truncation = 'only_first',\n",
        "                          max_length = 512,           # Pad & truncate all sentences.\n",
        "                          pad_to_max_length = True,\n",
        "                          return_attention_mask = True,   # Construct attn. masks.\n",
        "                          return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                    )\n",
        "      \n",
        "      # Add the encoded sentence to the list.    \n",
        "      input_ids.append(encoded_dict['input_ids'])\n",
        "      \n",
        "      # And its attention mask (simply differentiates padding from non-padding).\n",
        "      attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "  # Convert the lists into tensors.\n",
        "  input_ids = torch.cat(input_ids, dim=0)\n",
        "  attention_masks = torch.cat(attention_masks, dim=0)\n",
        "  labels = torch.from_numpy(labels)\n",
        "\n",
        "  return(input_ids, attention_masks, labels)\n",
        "\n",
        "input_ids_train, attention_masks_train, labels_train = tokenize(sentences_train, labels_train)\n",
        "input_ids_valid, attention_masks_valid, labels_valid = tokenize(sentences_valid, labels_valid)\n",
        "input_ids_test, attention_masks_test, labels_test = tokenize(sentences_test, labels_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading BERT tokenizer...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f4874d73664e471290ab0e583771bf0b",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (554 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (542 > 512). Running this sequence through the model will result in indexing errors\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z0SzIxf0s51S",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "87a65e59-fb39-42bc-f89a-7876127549d4"
      },
      "source": [
        "from torch.utils.data import TensorDataset, random_split\n",
        "\n",
        "# Combine the training inputs into a TensorDataset.\n",
        "dataset_train = TensorDataset(input_ids_train, attention_masks_train, labels_train)\n",
        "dataset_valid = TensorDataset(input_ids_valid, attention_masks_valid, labels_valid)\n",
        "dataset_test = TensorDataset(input_ids_test, attention_masks_test, labels_test)\n",
        "\n",
        "#Use the given training and validation datasets\n",
        "train_dataset, val_dataset = dataset_train, dataset_valid\n",
        "\n",
        "print('{:>5,} training samples'.format(len(train_dataset)))\n",
        "print('{:>5,} validation samples'.format(len(val_dataset)))\n",
        "print('{:>5,} test samples'.format(len(dataset_test)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "19,533 training samples\n",
            "2,763 validation samples\n",
            "2,542 test samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X-Gydj5OtXt6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "08e00448-0517-4656-85c2-0c65b38a5563"
      },
      "source": [
        "from transformers import BertForSequenceClassification, BertTokenizer\n",
        "output_dir = \"./\" + model_type + \"_\" + model_name + \"_save/\"\n",
        "\n",
        "# Load a trained model and vocabulary that you have fine-tuned\n",
        "model = BertForSequenceClassification.from_pretrained(output_dir)\n",
        "tokenizer = BertTokenizer.from_pretrained(output_dir)\n",
        "\n",
        "# Copy the model to the GPU.\n",
        "model.to(device)\n",
        "\n",
        "print(model_type + \"_\" + model_name + \" loaded...\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "pos_neg_model1 loaded...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_jHcY7NItPZI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        },
        "outputId": "d6803ccf-d341-423e-c964-965a1a82dc96"
      },
      "source": [
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "batch_size = 32\n",
        "\n",
        "def predict(dataset):\n",
        "\n",
        "  # Create the DataLoader for  dataset.\n",
        "  prediction_data = dataset\n",
        "  prediction_sampler = SequentialSampler(prediction_data)\n",
        "  prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)\n",
        "\n",
        "\n",
        "  # Prediction on test set\n",
        "\n",
        "  print('Predicting labels for {:,} sentences...'.format(len(dataset)))\n",
        "\n",
        "  # Put model in evaluation mode\n",
        "  model.eval()\n",
        "\n",
        "  # Tracking variables \n",
        "  predictions , true_labels = [], []\n",
        "\n",
        "  # Predict \n",
        "  for batch in prediction_dataloader:\n",
        "    # Add batch to GPU\n",
        "    batch = tuple(t.to(device) for t in batch)\n",
        "    \n",
        "    # Unpack the inputs from our dataloader\n",
        "    b_input_ids, b_input_mask, b_labels = batch\n",
        "    \n",
        "    # Telling the model not to compute or store gradients, saving memory and \n",
        "    # speeding up prediction\n",
        "    with torch.no_grad():\n",
        "        # Forward pass, calculate logit predictions\n",
        "        outputs = model(b_input_ids, token_type_ids=None, \n",
        "                        attention_mask=b_input_mask)\n",
        "\n",
        "    logits = outputs[0]\n",
        "\n",
        "    # Move logits and labels to CPU\n",
        "    logits = logits.detach().cpu().numpy()\n",
        "    label_ids = b_labels.to('cpu').numpy()\n",
        "    \n",
        "    # Store predictions and true labels\n",
        "    predictions.append(logits)\n",
        "    true_labels.append(label_ids)\n",
        "\n",
        "  print('DONE.')\n",
        "  return predictions, true_labels\n",
        "\n",
        "test_predictions, test_true_labels = predict(dataset_test)\n",
        "valid_predictions, valid_true_labels = predict(dataset_valid)\n",
        "train_predictions, train_true_labels = predict(dataset_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicting labels for 2,542 sentences...\n",
            "DONE.\n",
            "Predicting labels for 2,763 sentences...\n",
            "DONE.\n",
            "Predicting labels for 19,533 sentences...\n",
            "DONE.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ntNnvi6kve9R",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 598
        },
        "outputId": "64365594-06d7-4036-f075-1f8f0ab0b3fe"
      },
      "source": [
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "def metrics(predictions, true_labels):\n",
        "  for i in range(len(predictions)):\n",
        "    if i == 0:\n",
        "      pred_flat = np.argmax(predictions[i], axis=1).flatten()\n",
        "      confidence_flat = np.amax(predictions[i], axis=1).flatten()\n",
        "      labels_flat = true_labels[i].flatten()\n",
        "    else:\n",
        "      pred_flat = np.append(pred_flat, np.argmax(predictions[i], axis=1).flatten())\n",
        "      confidence_flat = np.append(confidence_flat, np.amax(predictions[i], axis=1).flatten())\n",
        "      labels_flat = np.append(labels_flat, true_labels[i].flatten())\n",
        "\n",
        "  if model_type == \"emotion\":\n",
        "    pred_flat = label2emotion(pred_flat)\n",
        "    labels_flat = label2emotion(labels_flat)\n",
        "  else:\n",
        "    pred_flat = label2category(pred_flat)\n",
        "    labels_flat = label2category(labels_flat)\n",
        "  print(\"Classwise Report\")\n",
        "  print(classification_report(labels_flat, pred_flat))\n",
        "  return pred_flat, confidence_flat, labels_flat\n",
        "print(\"Metrics on testing set\")\n",
        "pred_flat_test, confidence_flat_test, labels_flat_test = metrics(test_predictions, test_true_labels)\n",
        "print(\"Metrics on validation set\")\n",
        "pred_flat_valid, confidence_flat_valid, labels_flat_valid = metrics(valid_predictions, valid_true_labels)\n",
        "print(\"Metrics on training set\")\n",
        "pred_flat_train, confidence_flat_train, labels_flat_train = metrics(train_predictions, train_true_labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Metrics on testing set\n",
            "Classwise Report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.90      0.91      0.90      1227\n",
            "    positive       0.91      0.90      0.91      1315\n",
            "\n",
            "    accuracy                           0.91      2542\n",
            "   macro avg       0.91      0.91      0.91      2542\n",
            "weighted avg       0.91      0.91      0.91      2542\n",
            "\n",
            "Metrics on validation set\n",
            "Classwise Report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.90      0.90      0.90      1377\n",
            "    positive       0.90      0.90      0.90      1386\n",
            "\n",
            "    accuracy                           0.90      2763\n",
            "   macro avg       0.90      0.90      0.90      2763\n",
            "weighted avg       0.90      0.90      0.90      2763\n",
            "\n",
            "Metrics on training set\n",
            "Classwise Report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       1.00      1.00      1.00      9673\n",
            "    positive       1.00      1.00      1.00      9860\n",
            "\n",
            "    accuracy                           1.00     19533\n",
            "   macro avg       1.00      1.00      1.00     19533\n",
            "weighted avg       1.00      1.00      1.00     19533\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CYsYQdEAhX_J",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "outputId": "32327758-7681-41bc-a786-72b9908bd25c"
      },
      "source": [
        "if model_type == \"emotion\":\n",
        "  final_train_df['emotion_actual'] = pd.DataFrame(labels_flat_train, columns=['emotion_actual'])\n",
        "  final_train_df['emotion_pred'] = pd.DataFrame(pred_flat_train, columns=['emotion_pred'])\n",
        "  final_valid_df['emotion_actual'] = pd.DataFrame(labels_flat_valid, columns=['emotion_actual'])\n",
        "  final_valid_df['emotion_pred'] = pd.DataFrame(pred_flat_valid, columns=['emotion_pred'])\n",
        "  final_test_df['emotion_actual'] = pd.DataFrame(labels_flat_test, columns=['emotion_actual'])\n",
        "  final_test_df['emotion_pred'] = pd.DataFrame(pred_flat_test, columns=['emotion_pred'])\n",
        "else:\n",
        "  final_train_df = pd.DataFrame(sentences_train, columns=['sentences'])\n",
        "  final_train_df['pos_neg_actual'] = pd.DataFrame(labels_flat_train, columns=['pos_neg_actual'])\n",
        "  final_train_df['pos_neg_pred'] = pd.DataFrame(pred_flat_train, columns=['pos_neg_pred'])\n",
        "  final_valid_df = pd.DataFrame(sentences_valid, columns=['sentences'])\n",
        "  final_valid_df['pos_neg_actual'] = pd.DataFrame(labels_flat_valid, columns=['pos_neg_actual'])\n",
        "  final_valid_df['pos_neg_pred'] = pd.DataFrame(pred_flat_valid, columns=['pos_neg_pred'])\n",
        "  final_test_df = pd.DataFrame(sentences_test, columns=['sentences'])\n",
        "  final_test_df['pos_neg_actual'] = pd.DataFrame(labels_flat_test, columns=['pos_neg_actual'])\n",
        "  final_test_df['pos_neg_pred'] = pd.DataFrame(pred_flat_test, columns=['pos_neg_pred'])\n",
        "final_train_df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentences</th>\n",
              "      <th>pos_neg_actual</th>\n",
              "      <th>pos_neg_pred</th>\n",
              "      <th>emotion_actual</th>\n",
              "      <th>emotion_pred</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>I remember going to the fireworks with my best...</td>\n",
              "      <td>positive</td>\n",
              "      <td>positive</td>\n",
              "      <td>sentimental</td>\n",
              "      <td>sentimental</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>One year during christmas_comma_ i did not get...</td>\n",
              "      <td>negative</td>\n",
              "      <td>negative</td>\n",
              "      <td>sad</td>\n",
              "      <td>sad</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I have been in college for four years and am o...</td>\n",
              "      <td>positive</td>\n",
              "      <td>positive</td>\n",
              "      <td>hopeful</td>\n",
              "      <td>hopeful</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>You never know how happy you can be until you ...</td>\n",
              "      <td>positive</td>\n",
              "      <td>positive</td>\n",
              "      <td>joyful</td>\n",
              "      <td>joyful</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>the redsox have a chance to break the amount o...</td>\n",
              "      <td>positive</td>\n",
              "      <td>positive</td>\n",
              "      <td>impressed</td>\n",
              "      <td>impressed</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19525</th>\n",
              "      <td>living out in the country when it gets dark it...</td>\n",
              "      <td>negative</td>\n",
              "      <td>negative</td>\n",
              "      <td>afraid</td>\n",
              "      <td>afraid</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19526</th>\n",
              "      <td>I took my boots off after a long day of workin...</td>\n",
              "      <td>positive</td>\n",
              "      <td>positive</td>\n",
              "      <td>trusting</td>\n",
              "      <td>embarrassed</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19527</th>\n",
              "      <td>Anytime I see a mall_comma_ I get nostalgic ab...</td>\n",
              "      <td>positive</td>\n",
              "      <td>positive</td>\n",
              "      <td>nostalgic</td>\n",
              "      <td>nostalgic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19528</th>\n",
              "      <td>i cant wait to play the new madden_comma_ ive ...</td>\n",
              "      <td>positive</td>\n",
              "      <td>positive</td>\n",
              "      <td>anticipating</td>\n",
              "      <td>anticipating</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19529</th>\n",
              "      <td>I'm faithful I'm going down the right career p...</td>\n",
              "      <td>positive</td>\n",
              "      <td>positive</td>\n",
              "      <td>faithful</td>\n",
              "      <td>faithful</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>19530 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               sentences  ...  emotion_pred\n",
              "0      I remember going to the fireworks with my best...  ...   sentimental\n",
              "1      One year during christmas_comma_ i did not get...  ...           sad\n",
              "2      I have been in college for four years and am o...  ...       hopeful\n",
              "3      You never know how happy you can be until you ...  ...        joyful\n",
              "4      the redsox have a chance to break the amount o...  ...     impressed\n",
              "...                                                  ...  ...           ...\n",
              "19525  living out in the country when it gets dark it...  ...        afraid\n",
              "19526  I took my boots off after a long day of workin...  ...   embarrassed\n",
              "19527  Anytime I see a mall_comma_ I get nostalgic ab...  ...     nostalgic\n",
              "19528  i cant wait to play the new madden_comma_ ive ...  ...  anticipating\n",
              "19529  I'm faithful I'm going down the right career p...  ...      faithful\n",
              "\n",
              "[19530 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 139
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Tq02Wc3lNJk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qc62OZlhox9m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "final_train_df.to_csv(\"Data/\" + model_name + \"_\" + \"predictions_train.csv\", index=False)\n",
        "final_valid_df.to_csv(\"Data/\" + model_name + \"_\" + \"predictions_valid.csv\", index=False)\n",
        "final_test_df.to_csv(\"Data/\" + model_name + \"_\" + \"predictions_test.csv\", index=False)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}