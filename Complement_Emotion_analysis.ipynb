{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Complement Emotion analysis.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyM8tD9WH4oG5T200wjROMyX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "1d78a2aac310402c9bb17dc5ede225bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_780611a99ff946089cd5f996a96eaa1c",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_c5bab05d6221468580c94f3bb1f05a74",
              "IPY_MODEL_b6363ee58735411f98a35333197e538c"
            ]
          }
        },
        "780611a99ff946089cd5f996a96eaa1c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c5bab05d6221468580c94f3bb1f05a74": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_4f4b91fbed794d8babb7bac2fb3d79fb",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5a489796b3bf426382358fce2c3bfaaf"
          }
        },
        "b6363ee58735411f98a35333197e538c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_c316d88a46af4e0c8bd4e3b03c899fa2",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 232k/232k [00:00&lt;00:00, 304kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4071e3d7576649a99adc159049c9d4b1"
          }
        },
        "4f4b91fbed794d8babb7bac2fb3d79fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5a489796b3bf426382358fce2c3bfaaf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c316d88a46af4e0c8bd4e3b03c899fa2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4071e3d7576649a99adc159049c9d4b1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/omkarpat/EmpatheticDialoguesEmotionDetection/blob/master/Complement_Emotion_analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y9-Pp3jxkOWu",
        "colab_type": "code",
        "outputId": "9a1418e6-72fa-47a6-c843-6bc22e795107",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        }
      },
      "source": [
        "# Colab settings/mount\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "%cd gdrive/My\\ Drive/CSE\\ 245\\ Project"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·\n",
            "Mounted at /content/gdrive\n",
            "/content/gdrive/My Drive/CSE 245 Project\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GprZk0zDoBPg",
        "colab_type": "code",
        "outputId": "3e7ac1c5-fdc1-4fa1-f192-e608369204d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 809
        }
      },
      "source": [
        "!ls Data"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "'Data Exploration.ipynb'\n",
            " data_fixed_train_complement_analysis.csv\n",
            " data_fixed_train.json\n",
            " data_sample_100.json\n",
            " data_sample_10_complement_analysis.csv\n",
            " data_sample_10.json\n",
            " data_sample_10_processed.json\n",
            " data_sample_fixed_processed_final.json\n",
            " data_sample_fixed_processed_model1_final.csv\n",
            " data_sample_fixed_processed_model2_final.csv\n",
            " data_sample_fixed_processed_model3_final.csv\n",
            " data_sample_fixed_processed_model4_final.csv\n",
            " fixed\n",
            " fixed_test.csv\n",
            " fixed_test.json\n",
            " fixed_train_516.csv\n",
            " fixed_valid.csv\n",
            " fixed_valid.json\n",
            "'informative words.ipynb'\n",
            " model1_predictions_test.csv\n",
            " model1_predictions_train.csv\n",
            " model1_predictions_valid.csv\n",
            " model2_predictions_test.csv\n",
            " model2_predictions_train.csv\n",
            " model2_predictions_valid.csv\n",
            " model3_predictions_test.csv\n",
            " model3_predictions_train.csv\n",
            " model3_predictions_valid.csv\n",
            " model4_predictions_test.csv\n",
            " model4_predictions_train.csv\n",
            " model4_predictions_valid.csv\n",
            "'Model Metrics.gsheet'\n",
            " Raw\n",
            " test_fixed_processed_final.json\n",
            " test_fixed_processed_model1_final.csv\n",
            " test_fixed_processed_model2_final.csv\n",
            " test_fixed_processed_model3_final.csv\n",
            " test_fixed_processed_model4_final.csv\n",
            " valence_groupings.txt\n",
            " valid.csv\n",
            " valid_fixed_processed_final.json\n",
            " valid_fixed_processed_model1_final.csv\n",
            " valid_fixed_processed_model2_final.csv\n",
            " valid_fixed_processed_model3_final.csv\n",
            " valid_fixed_processed_model4_final.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7jHk-25CnNZ4",
        "colab_type": "code",
        "outputId": "d1d4e594-2065-47c6-fbca-fbef4e5d7a2b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 615
        }
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/48/35/ad2c5b1b8f99feaaf9d7cdadaeef261f098c6e1a6a2935d4d07662a6b780/transformers-2.11.0-py3-none-any.whl (674kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 675kB 2.7MB/s \n",
            "\u001b[?25hCollecting tokenizers==0.7.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/14/e5/a26eb4716523808bb0a799fcfdceb6ebf77a18169d9591b2f46a9adb87d9/tokenizers-0.7.0-cp36-cp36m-manylinux1_x86_64.whl (3.8MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3.8MB 16.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 890kB 28.2MB/s \n",
            "\u001b[?25hCollecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/68/e5/0366f50a00db181f4b7f3bdc408fc7c4177657f5bf45cb799b79fb4ce15c/sentencepiece-0.1.92-cp36-cp36m-manylinux1_x86_64.whl (1.2MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.2MB 38.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (1.12.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.9)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.4.5.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.15.1)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893260 sha256=b9300982873f8908680c8a32a880d682568dc6d8d97ab65a040814d01bc71562\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: tokenizers, sacremoses, sentencepiece, transformers\n",
            "Successfully installed sacremoses-0.0.43 sentencepiece-0.1.92 tokenizers-0.7.0 transformers-2.11.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d_nn3RYMncMX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset_name = \"data_fixed_train_complement_analysis\"\n",
        "speaker_model_name = \"model3\"\n",
        "listener_model_name = \"model2\"\n",
        "model_type = \"emotion\" #pos_neg or emotion"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c2FQw1KNn1fM",
        "colab_type": "code",
        "outputId": "fb6a4ef4-73f8-4cd1-da3e-7e8eb3269007",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Get the GPU device name.\n",
        "device_name = tf.test.gpu_device_name()\n",
        "\n",
        "# The device name should look like the following:\n",
        "if device_name == '/device:GPU:0':\n",
        "    print('Found GPU at: {}'.format(device_name))\n",
        "else:\n",
        "    raise SystemError('GPU device not found')\n",
        "\n",
        "import torch\n",
        "\n",
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():    \n",
        "\n",
        "    # Tell PyTorch to use the GPU.    \n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n",
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla P100-PCIE-16GB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "renu1EMVoOZX",
        "colab_type": "code",
        "outputId": "7cd664f4-a367-43f4-e600-6d8ac25a2277",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "import json\n",
        "with open(\"Data/data_sample_10.json\") as infile:\n",
        "  data = json.load(infile)\n",
        "print(data['1022'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'prompt': 'We (family friends) planned a holiday trip to go for the last weekend. I was preparing for that like packing dress and getting ready to it. Unfortunately one of my cousin was unable to come due to his personal reasons. So we just cancelled the trip. I was feeling sad for this trip cancellation. ', 'emotion': 'sad', 'dialog': [{'speaker': 43, 'utterance': 'My holiday trip has cancelled. I was feeling low for it. '}, {'speaker': 167, 'utterance': 'That is bad news and hard to deal with.'}, {'speaker': 43, 'utterance': 'yeah. Waiting for the next holiday.'}, {'speaker': 167, 'utterance': 'I sure hope you have a wonderful next Holiday trip very soon.'}, {'speaker': 43, 'utterance': 'thank you! have a nice day'}]}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AnfbzV_etiqK",
        "colab_type": "code",
        "outputId": "0d810630-90e8-4341-de26-f4b7b5b37132",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "print(data.keys())\n",
        "print(data['2103'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dict_keys(['1022', '2103', '4072', '9710', '11290', '11572', '13042', '13485', '18577', '21184'])\n",
            "{'prompt': 'My cousin bought a really pretty shirt that I had been wanting.', 'emotion': 'jealous', 'dialog': [{'speaker': 226, 'utterance': 'My cousin bought a really pretty shirt that I had been wanting'}, {'speaker': 10, 'utterance': 'My cousin bought a really pretty shirt that I had been wanting'}, {'speaker': 226, 'utterance': 'that is not fun_comma_ does that mean you cannot get it now?'}, {'speaker': 10, 'utterance': \"No I can but I didn't want her to have it and not me.\"}, {'speaker': 226, 'utterance': 'that is no fun_comma_ does that mean you cannot buy it now?'}, {'speaker': 10, 'utterance': \"No I can but I didn't want her to have it and not me.\"}]}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bWKkiQeDoPon",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open(\"Data/data_fixed_train.json\",\"r\") as infile:\n",
        "  data = json.load(infile)\n",
        "  with open(\"Data/data_complement_analysis.csv\",\"w\") as outfile:\n",
        "    outfile.write(\"emotion|speaker_utterance|listener_utterance\\n\")\n",
        "    for key in data.keys():\n",
        "      dialog = data[key]['dialog']\n",
        "      emotion = data[key]['emotion']\n",
        "      i = 0\n",
        "      while i < len(dialog):\n",
        "        speaker_utterance = str(dialog[i]['utterance']).replace(\"|\",\"\").replace(\"_comma_\",\",\")\n",
        "        listener_utterance = str(dialog[i+1]['utterance']).replace(\"|\",\"\").replace(\"_comma_\",\",\") if i + 1 < len(dialog) else \"\"\n",
        "        line = \"%s|%s|%s\\n\" % (emotion, speaker_utterance, listener_utterance)\n",
        "        outfile.write(line)\n",
        "        #print(line)\n",
        "        i += 2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7yQThmpBCSiO",
        "colab_type": "code",
        "outputId": "3bd44667-b70a-4c66-e866-7573c5c3e48d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        }
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "train_filename = \"Data/\" + dataset_name + \".csv\"\n",
        "train_df = pd.read_csv(train_filename, sep='|', error_bad_lines=False)\n",
        "train_df = train_df.dropna()\n",
        "train_df"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>emotion</th>\n",
              "      <th>speaker_utterance</th>\n",
              "      <th>listener_utterance</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>sentimental</td>\n",
              "      <td>I remember going to see the fireworks with my ...</td>\n",
              "      <td>Was this a friend you were in love with, or ju...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>sentimental</td>\n",
              "      <td>This was a best friend. I miss her.</td>\n",
              "      <td>Where has she gone?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>sentimental</td>\n",
              "      <td>We no longer talk.</td>\n",
              "      <td>Oh was this something that happened because of...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>sad</td>\n",
              "      <td>During christmas a few years ago, I did not ge...</td>\n",
              "      <td>Wow, that must be terrible, I cannot imagine, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>sad</td>\n",
              "      <td>Since that day christmas has not been a good t...</td>\n",
              "      <td>Wow, I am sorry to hear that, I wish I could m...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43904</th>\n",
              "      <td>nostalgic</td>\n",
              "      <td>Yeah! It's weird, malls feel like ghost towns,...</td>\n",
              "      <td>I live in a very large city on the east coast....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43906</th>\n",
              "      <td>anticipating</td>\n",
              "      <td>ive been waiting for months for the new madden...</td>\n",
              "      <td>Heck yeah! I myself have never been into madde...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43907</th>\n",
              "      <td>anticipating</td>\n",
              "      <td>i love 2k, proam is the best!</td>\n",
              "      <td>I've been playing it since I was a kid, but I ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43908</th>\n",
              "      <td>faithful</td>\n",
              "      <td>I'm faithful I'm going down the right career p...</td>\n",
              "      <td>that is a great feeling, what are you pusuing?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43909</th>\n",
              "      <td>faithful</td>\n",
              "      <td>Web Development and Design.  Something I've be...</td>\n",
              "      <td>man thats awesome, i have a friend who is in t...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>40245 rows Ã— 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            emotion  ...                                 listener_utterance\n",
              "0       sentimental  ...  Was this a friend you were in love with, or ju...\n",
              "1       sentimental  ...                                Where has she gone?\n",
              "2       sentimental  ...  Oh was this something that happened because of...\n",
              "3               sad  ...  Wow, that must be terrible, I cannot imagine, ...\n",
              "4               sad  ...  Wow, I am sorry to hear that, I wish I could m...\n",
              "...             ...  ...                                                ...\n",
              "43904     nostalgic  ...  I live in a very large city on the east coast....\n",
              "43906  anticipating  ...  Heck yeah! I myself have never been into madde...\n",
              "43907  anticipating  ...  I've been playing it since I was a kid, but I ...\n",
              "43908      faithful  ...     that is a great feeling, what are you pusuing?\n",
              "43909      faithful  ...  man thats awesome, i have a friend who is in t...\n",
              "\n",
              "[40245 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1qM9deSmDdnQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "category2index = {\n",
        "    \"invalid\":0,\n",
        "    \"sentimental\":1,\n",
        "    \"sad\":2,\n",
        "    \"hopeful\":3,\n",
        "    \"joyful\":4,\n",
        "    \"impressed\":5,\n",
        "    \"terrified\":6,\n",
        "    \"proud\":7,\n",
        "    \"afraid\":8,\n",
        "    \"grateful\":9,\n",
        "    \"lonely\":10,\n",
        "    \"surprised\":11,\n",
        "    \"anxious\":12,\n",
        "    \"guilty\":13,\n",
        "    \"trusting\":14,\n",
        "    \"nostalgic\":15,\n",
        "    \"excited\":16,\n",
        "    \"disgusted\":17,\n",
        "    \"caring\":18,\n",
        "    \"furious\":19,\n",
        "    \"angry\":20,\n",
        "    \"prepared\":21,\n",
        "    \"disappointed\":22,\n",
        "    \"faithful\":23,\n",
        "    \"confident\":24,\n",
        "    \"apprehensive\":25,\n",
        "    \"jealous\":26,\n",
        "    \"embarrassed\":27,\n",
        "    \"devastated\":28,\n",
        "    \"annoyed\":29,\n",
        "    \"ashamed\":30,\n",
        "    \"content\":31,\n",
        "    \"anticipating\":32\n",
        "}\n",
        "index2category = {}\n",
        "for key, value in category2index.items():\n",
        "  index2category[value] = key\n",
        "\n",
        "def category2label(category):\n",
        "  for key in category2index.keys():\n",
        "    if key == category:\n",
        "      return category2index[key]\n",
        "  return 0\n",
        "\n",
        "def label2emotion(labels):\n",
        "  emotion_list = []\n",
        "  for label in labels:\n",
        "    emotion_list.append(index2category[label])\n",
        "  return emotion_list"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Z400TGiDi2u",
        "colab_type": "code",
        "outputId": "d1412d28-b9b1-410e-c78b-b6962979aec9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 392
        }
      },
      "source": [
        "print('Number of training sentences: {:,}\\n'.format(train_df.shape[0]))\n",
        "if model_type == \"emotion\":\n",
        "  train_df['orignial_label'] = train_df['emotion'].apply(lambda x: int(category2label(x.lower())))\n",
        "\n",
        "# Display 10 random rows from the data.\n",
        "train_df.sample(10)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training sentences: 40,245\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>emotion</th>\n",
              "      <th>speaker_utterance</th>\n",
              "      <th>listener_utterance</th>\n",
              "      <th>orignial_label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>41188</th>\n",
              "      <td>grateful</td>\n",
              "      <td>I am so lucky to have the things I have. My 10...</td>\n",
              "      <td>Wow, it sounds like you have a lot to be grate...</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40201</th>\n",
              "      <td>lonely</td>\n",
              "      <td>I guess, I got through it</td>\n",
              "      <td>Maybe next weekend will be better for you!</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12586</th>\n",
              "      <td>grateful</td>\n",
              "      <td>my friend helped me move last week</td>\n",
              "      <td>Cool, how long did that take?</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39168</th>\n",
              "      <td>furious</td>\n",
              "      <td>Last week I cleaned my house when my kids were...</td>\n",
              "      <td>That is so satisfying. I hope they don't mess ...</td>\n",
              "      <td>19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6628</th>\n",
              "      <td>ashamed</td>\n",
              "      <td>I cheated on my math test today.</td>\n",
              "      <td>Oh man. Must be feeling pretty guilty by now.</td>\n",
              "      <td>30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13348</th>\n",
              "      <td>terrified</td>\n",
              "      <td>The best I can do is incorporate humor into my...</td>\n",
              "      <td>I'm sure you'll be fine, just try to practice ...</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35470</th>\n",
              "      <td>surprised</td>\n",
              "      <td>I was an editor, so I designed and wrote up th...</td>\n",
              "      <td>That is wonderful. I use to love English class...</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35543</th>\n",
              "      <td>disappointed</td>\n",
              "      <td>That's a good idea, I didn't think about that ...</td>\n",
              "      <td>Im always living on a budget so even if you co...</td>\n",
              "      <td>22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13606</th>\n",
              "      <td>anxious</td>\n",
              "      <td>Yeah I feel the same way, then it ends up bein...</td>\n",
              "      <td>Similar to most things, yea. What was wrong wi...</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6540</th>\n",
              "      <td>disappointed</td>\n",
              "      <td>They're leaving too much work behind for me to...</td>\n",
              "      <td>See. They will only hinder the overall perform...</td>\n",
              "      <td>22</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            emotion  ... orignial_label\n",
              "41188      grateful  ...              9\n",
              "40201        lonely  ...             10\n",
              "12586      grateful  ...              9\n",
              "39168       furious  ...             19\n",
              "6628        ashamed  ...             30\n",
              "13348     terrified  ...              6\n",
              "35470     surprised  ...             11\n",
              "35543  disappointed  ...             22\n",
              "13606       anxious  ...             12\n",
              "6540   disappointed  ...             22\n",
              "\n",
              "[10 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OCW765A8D90O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "speaker_sentences_train = train_df.speaker_utterance.values\n",
        "listener_sentences_train = train_df.listener_utterance.values\n",
        "labels_train = train_df.orignial_label.values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J8q_mvEuEO8-",
        "colab_type": "code",
        "outputId": "b910e046-3cec-4f93-e983-ff4d626abcb0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84,
          "referenced_widgets": [
            "1d78a2aac310402c9bb17dc5ede225bd",
            "780611a99ff946089cd5f996a96eaa1c",
            "c5bab05d6221468580c94f3bb1f05a74",
            "b6363ee58735411f98a35333197e538c",
            "4f4b91fbed794d8babb7bac2fb3d79fb",
            "5a489796b3bf426382358fce2c3bfaaf",
            "c316d88a46af4e0c8bd4e3b03c899fa2",
            "4071e3d7576649a99adc159049c9d4b1"
          ]
        }
      },
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "# Load the BERT tokenizer.\n",
        "print('Loading BERT tokenizer...')\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
        "\n",
        "longer_list = []\n",
        "for index, sent in enumerate(speaker_sentences_train):\n",
        "  if len(tokenizer.encode(sent, add_special_tokens=True)) > 500:\n",
        "    longer_list.append(index)\n",
        "speaker_sentences_train = np.delete(speaker_sentences_train, longer_list)\n",
        "\n",
        "longer_list = []\n",
        "for index, sent in enumerate(listener_sentences_train):\n",
        "  if len(tokenizer.encode(sent, add_special_tokens=True)) > 500:\n",
        "    longer_list.append(index)\n",
        "listener_sentences_train = np.delete(listener_sentences_train, longer_list)\n",
        "from transformers import BertTokenizer\n",
        "\n",
        "def tokenize(sentences, labels):\n",
        "  # Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "  input_ids = []\n",
        "  attention_masks = []\n",
        "\n",
        "  # For every sentence...\n",
        "  for sent in sentences:\n",
        "      # `encode_plus` will:\n",
        "      #   (1) Tokenize the sentence.\n",
        "      #   (2) Prepend the `[CLS]` token to the start.\n",
        "      #   (3) Append the `[SEP]` token to the end.\n",
        "      #   (4) Map tokens to their IDs.\n",
        "      #   (5) Pad or truncate the sentence to `max_length`\n",
        "      #   (6) Create attention masks for [PAD] tokens.\n",
        "\n",
        "      encoded_dict = tokenizer.encode_plus(\n",
        "                          sent,                      # Sentence to encode.\n",
        "                          add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                          max_length = 256,           # Pad & truncate all sentences.\n",
        "                          pad_to_max_length = True,\n",
        "                          return_attention_mask = True,   # Construct attn. masks.\n",
        "                          return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                    )\n",
        "      \n",
        "      # Add the encoded sentence to the list.    \n",
        "      input_ids.append(encoded_dict['input_ids'])\n",
        "      \n",
        "      # And its attention mask (simply differentiates padding from non-padding).\n",
        "      attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "  # Convert the lists into tensors.\n",
        "  input_ids = torch.cat(input_ids, dim=0)\n",
        "  attention_masks = torch.cat(attention_masks, dim=0)\n",
        "  labels = torch.from_numpy(labels)\n",
        "\n",
        "  return(input_ids, attention_masks, labels)\n",
        "\n",
        "speaker_input_ids_train, speaker_attention_masks_train, speaker_labels_train = tokenize(speaker_sentences_train, labels_train)\n",
        "listener_input_ids_train, listener_attention_masks_train, listener_labels_train = tokenize(listener_sentences_train, labels_train)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading BERT tokenizer...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1d78a2aac310402c9bb17dc5ede225bd",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descriptiâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nd0MCU-14fac",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "063e247c-8f8b-4a72-e274-71cb409786ee"
      },
      "source": [
        "from torch.utils.data import TensorDataset, random_split\n",
        "\n",
        "# Combine the training inputs into a TensorDataset.\n",
        "speaker_dataset_train = TensorDataset(speaker_input_ids_train, speaker_attention_masks_train, speaker_labels_train)\n",
        "listener_dataset_train = TensorDataset(listener_input_ids_train, listener_attention_masks_train, listener_labels_train)\n",
        "\n",
        "print('{:>5,} training samples'.format(len(speaker_dataset_train)))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "40,245 training samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qomhihuf5gki",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "4df8e54f-8dda-4d1f-d284-4d83945de6cb"
      },
      "source": [
        "from transformers import BertForSequenceClassification, BertTokenizer\n",
        "output_dir = \"./\" + model_type + \"_\" + speaker_model_name + \"_save/\"\n",
        "\n",
        "# Load a trained model and vocabulary that you have fine-tuned\n",
        "model = BertForSequenceClassification.from_pretrained(output_dir)\n",
        "tokenizer = BertTokenizer.from_pretrained(output_dir)\n",
        "\n",
        "# Copy the model to the GPU.\n",
        "model.to(device)\n",
        "\n",
        "print(model_type + \"_\" + speaker_model_name + \" loaded...\")"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "emotion_model3 loaded...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oMbGYsRB5u51",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        },
        "outputId": "608f29a6-7814-4cf1-9904-ad1ecc183abb"
      },
      "source": [
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "batch_size = 32\n",
        "\n",
        "def predict(dataset):\n",
        "\n",
        "  # Create the DataLoader for  dataset.\n",
        "  prediction_data = dataset\n",
        "  prediction_sampler = SequentialSampler(prediction_data)\n",
        "  prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)\n",
        "\n",
        "\n",
        "  # Prediction on test set\n",
        "\n",
        "  print('Predicting labels for {:,} sentences...'.format(len(dataset)))\n",
        "\n",
        "  # Put model in evaluation mode\n",
        "  model.eval()\n",
        "\n",
        "  # Tracking variables \n",
        "  predictions , true_labels, speaker_utterance = [], [], []\n",
        "\n",
        "  # Predict \n",
        "  for batch in prediction_dataloader:\n",
        "    # Add batch to GPU\n",
        "    batch = tuple(t.to(device) for t in batch)\n",
        "    \n",
        "    # Unpack the inputs from our dataloader\n",
        "    b_input_ids, b_input_mask, b_labels = batch\n",
        "    \n",
        "    # Telling the model not to compute or store gradients, saving memory and \n",
        "    # speeding up prediction\n",
        "    with torch.no_grad():\n",
        "        # Forward pass, calculate logit predictions\n",
        "        outputs = model(b_input_ids, token_type_ids=None, \n",
        "                        attention_mask=b_input_mask)\n",
        "\n",
        "    logits = outputs[0]\n",
        "\n",
        "    # Move logits and labels to CPU\n",
        "    logits = logits.detach().cpu().numpy()\n",
        "    label_ids = b_labels.to('cpu').numpy()\n",
        "    \n",
        "    # Store predictions and true labels\n",
        "    predictions.append(logits)\n",
        "    true_labels.append(label_ids)\n",
        "\n",
        "  print('DONE.')\n",
        "  return predictions, true_labels\n",
        "\n",
        "speaker_train_predictions, speaker_train_true_labels = predict(speaker_dataset_train)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicting labels for 40,245 sentences...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-86d6b2ac2f74>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     48\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrue_labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m \u001b[0mspeaker_train_predictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspeaker_train_true_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspeaker_dataset_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-14-86d6b2ac2f74>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(dataset)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;31m# Move logits and labels to CPU\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m     \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m     \u001b[0mlabel_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb_labels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cpu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8nvnHeVP8fwT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 220
        },
        "outputId": "1940fe64-cce8-4319-f84c-f84a24c9926e"
      },
      "source": [
        "def predictions2labels(predictions):\n",
        "  for i in range(len(predictions)):\n",
        "    if i == 0:\n",
        "      pred_flat = np.argmax(predictions[i], axis=1).flatten()\n",
        "    else:\n",
        "      pred_flat = np.append(pred_flat, np.argmax(predictions[i], axis=1).flatten())\n",
        "  return label2emotion(pred_flat)\n",
        "train_df['emotion_speaker'] = pd.DataFrame(predictions2labels(speaker_train_predictions), columns=['emotion_speaker'])\n",
        "train_df.sample(10)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-d9ffd7cc6558>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m       \u001b[0mpred_flat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_flat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mlabel2emotion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_flat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mtrain_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'emotion_speaker'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions2labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspeaker_train_predictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'emotion_speaker'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HkEa_zM18VNR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "outputId": "fe9d6778-adcb-43c1-e687-827f69182df9"
      },
      "source": [
        "del model\n",
        "torch.cuda.empty_cache()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-b0cec479cb08>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mdel\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yNUMKZnv561W",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "a2724e4f-7d6c-4254-9e31-2c58f5892566"
      },
      "source": [
        "from transformers import BertForSequenceClassification, BertTokenizer\n",
        "output_dir = \"./\" + model_type + \"_\" + listener_model_name + \"_save/\"\n",
        "\n",
        "# Load a trained model and vocabulary that you have fine-tuned\n",
        "model = BertForSequenceClassification.from_pretrained(output_dir)\n",
        "tokenizer = BertTokenizer.from_pretrained(output_dir)\n",
        "\n",
        "# Copy the model to the GPU.\n",
        "model.to(device)\n",
        "\n",
        "print(model_type + \"_\" + listener_model_name + \" loaded...\")"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "emotion_model2 loaded...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KcXqMviA5-q3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "8a7c2b6b-4d1d-4aaf-813a-eb159fc136b5"
      },
      "source": [
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "batch_size = 32\n",
        "\n",
        "def predict(dataset):\n",
        "\n",
        "  # Create the DataLoader for  dataset.\n",
        "  prediction_data = dataset\n",
        "  prediction_sampler = SequentialSampler(prediction_data)\n",
        "  prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)\n",
        "\n",
        "\n",
        "  # Prediction on test set\n",
        "\n",
        "  print('Predicting labels for {:,} sentences...'.format(len(dataset)))\n",
        "\n",
        "  # Put model in evaluation mode\n",
        "  model.eval()\n",
        "\n",
        "  # Tracking variables \n",
        "  predictions , true_labels = [], []\n",
        "\n",
        "  # Predict \n",
        "  for batch in prediction_dataloader:\n",
        "    # Add batch to GPU\n",
        "    batch = tuple(t.to(device) for t in batch)\n",
        "    \n",
        "    # Unpack the inputs from our dataloader\n",
        "    b_input_ids, b_input_mask, b_labels = batch\n",
        "    \n",
        "    # Telling the model not to compute or store gradients, saving memory and \n",
        "    # speeding up prediction\n",
        "    with torch.no_grad():\n",
        "        # Forward pass, calculate logit predictions\n",
        "        outputs = model(b_input_ids, token_type_ids=None, \n",
        "                        attention_mask=b_input_mask)\n",
        "\n",
        "    logits = outputs[0]\n",
        "\n",
        "    # Move logits and labels to CPU\n",
        "    logits = logits.detach().cpu().numpy()\n",
        "    label_ids = b_labels.to('cpu').numpy()\n",
        "    \n",
        "    # Store predictions and true labels\n",
        "    predictions.append(logits)\n",
        "    true_labels.append(label_ids)\n",
        "\n",
        "  print('DONE.')\n",
        "  return predictions, true_labels\n",
        "\n",
        "listener_train_predictions, listener_train_true_labels = predict(listener_dataset_train)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicting labels for 40,245 sentences...\n",
            "DONE.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wrAti4A36tWP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "42396b8d-9122-4092-983d-310bfa29c46b"
      },
      "source": [
        "train_df['emotion_listener'] = pd.DataFrame(predictions2labels(listener_train_predictions), columns=['emotion_listener'])\n",
        "train_df.sample(10)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>emotion</th>\n",
              "      <th>speaker_utterance</th>\n",
              "      <th>listener_utterance</th>\n",
              "      <th>orignial_label</th>\n",
              "      <th>emotion_speaker</th>\n",
              "      <th>emotion_listener</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>24462</th>\n",
              "      <td>devastated</td>\n",
              "      <td>It is really sad, I had to call and order a ne...</td>\n",
              "      <td>Scary situation loosing a card...Hopefully you...</td>\n",
              "      <td>28</td>\n",
              "      <td>proud</td>\n",
              "      <td>surprised</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28117</th>\n",
              "      <td>sentimental</td>\n",
              "      <td>They live in the city. I just like the memorie...</td>\n",
              "      <td>Nice I'm in TX and my fam's in MN.  I try to v...</td>\n",
              "      <td>1</td>\n",
              "      <td>excited</td>\n",
              "      <td>prepared</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21167</th>\n",
              "      <td>content</td>\n",
              "      <td>Absolutely! I can get so much done, but I real...</td>\n",
              "      <td>That's not surprising! Are you thinking about ...</td>\n",
              "      <td>31</td>\n",
              "      <td>embarrassed</td>\n",
              "      <td>grateful</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>527</th>\n",
              "      <td>content</td>\n",
              "      <td>I recently had a child and my marriage is thri...</td>\n",
              "      <td>Great news.  Kids are always an exciting adven...</td>\n",
              "      <td>31</td>\n",
              "      <td>joyful</td>\n",
              "      <td>caring</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34962</th>\n",
              "      <td>apprehensive</td>\n",
              "      <td>I'm starting a new job in September!</td>\n",
              "      <td>That's awesome. What kind of job?</td>\n",
              "      <td>25</td>\n",
              "      <td>grateful</td>\n",
              "      <td>trusting</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10686</th>\n",
              "      <td>prepared</td>\n",
              "      <td>I am ready to go on Jeopardy.</td>\n",
              "      <td>when do you go?</td>\n",
              "      <td>21</td>\n",
              "      <td>afraid</td>\n",
              "      <td>angry</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28520</th>\n",
              "      <td>nostalgic</td>\n",
              "      <td>Yeah. Im pretty sure they think I was born in ...</td>\n",
              "      <td>Right, it's hard to imagine there was a time b...</td>\n",
              "      <td>15</td>\n",
              "      <td>surprised</td>\n",
              "      <td>anxious</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28963</th>\n",
              "      <td>trusting</td>\n",
              "      <td>I let my cousin look after my dog whilst I wen...</td>\n",
              "      <td>Oh nice, how did it go?</td>\n",
              "      <td>14</td>\n",
              "      <td>apprehensive</td>\n",
              "      <td>prepared</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40588</th>\n",
              "      <td>devastated</td>\n",
              "      <td>I am so hurt right now.</td>\n",
              "      <td>Forget him. There are soo many girls out there.</td>\n",
              "      <td>28</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2112</th>\n",
              "      <td>apprehensive</td>\n",
              "      <td>I have been preparing for grad school and it i...</td>\n",
              "      <td>I just got in a few months ago, best of luck m...</td>\n",
              "      <td>25</td>\n",
              "      <td>devastated</td>\n",
              "      <td>sad</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            emotion  ... emotion_listener\n",
              "24462    devastated  ...        surprised\n",
              "28117   sentimental  ...         prepared\n",
              "21167       content  ...         grateful\n",
              "527         content  ...           caring\n",
              "34962  apprehensive  ...         trusting\n",
              "10686      prepared  ...            angry\n",
              "28520     nostalgic  ...          anxious\n",
              "28963      trusting  ...         prepared\n",
              "40588    devastated  ...              NaN\n",
              "2112   apprehensive  ...              sad\n",
              "\n",
              "[10 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    }
  ]
}