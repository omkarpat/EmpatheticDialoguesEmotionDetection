{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Complement Emotion analysis.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNa92M/DcM7MMOqDbNXRaa3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/omkarpat/EmpatheticDialoguesEmotionDetection/blob/master/Complement_Emotion_analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y9-Pp3jxkOWu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "outputId": "ea5d4a01-1862-405c-f297-3f121dc882dd"
      },
      "source": [
        "# Colab settings/mount\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "%cd gdrive/My\\ Drive/CSE\\ 245\\ Project"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n",
            "/content/gdrive/My Drive/CSE 245 Project\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GprZk0zDoBPg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 774
        },
        "outputId": "a2c4ce27-6ad3-4be6-a5f7-04175dc1e726"
      },
      "source": [
        "!ls Data"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "'Data Exploration.ipynb'\n",
            " data_fixed_train.json\n",
            " data_sample_100.json\n",
            " data_sample_10.json\n",
            " data_sample_10_processed.json\n",
            " data_sample_fixed_processed_final.json\n",
            " data_sample_fixed_processed_model1_final.csv\n",
            " data_sample_fixed_processed_model2_final.csv\n",
            " data_sample_fixed_processed_model3_final.csv\n",
            " data_sample_fixed_processed_model4_final.csv\n",
            " fixed\n",
            " fixed_test.csv\n",
            " fixed_test.json\n",
            " fixed_train_516.csv\n",
            " fixed_valid.csv\n",
            " fixed_valid.json\n",
            "'informative words.ipynb'\n",
            " model1_predictions_test.csv\n",
            " model1_predictions_train.csv\n",
            " model1_predictions_valid.csv\n",
            " model2_predictions_test.csv\n",
            " model2_predictions_train.csv\n",
            " model2_predictions_valid.csv\n",
            " model3_predictions_test.csv\n",
            " model3_predictions_train.csv\n",
            " model3_predictions_valid.csv\n",
            " model4_predictions_test.csv\n",
            " model4_predictions_train.csv\n",
            " model4_predictions_valid.csv\n",
            "'Model Metrics.gsheet'\n",
            " Raw\n",
            " test_fixed_processed_final.json\n",
            " test_fixed_processed_model1_final.csv\n",
            " test_fixed_processed_model2_final.csv\n",
            " test_fixed_processed_model3_final.csv\n",
            " test_fixed_processed_model4_final.csv\n",
            " valence_groupings.txt\n",
            " valid.csv\n",
            " valid_fixed_processed_final.json\n",
            " valid_fixed_processed_model1_final.csv\n",
            " valid_fixed_processed_model2_final.csv\n",
            " valid_fixed_processed_model3_final.csv\n",
            " valid_fixed_processed_model4_final.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7jHk-25CnNZ4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 615
        },
        "outputId": "0e225b68-4656-4a9e-cf39-c916b61c678d"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/48/35/ad2c5b1b8f99feaaf9d7cdadaeef261f098c6e1a6a2935d4d07662a6b780/transformers-2.11.0-py3-none-any.whl (674kB)\n",
            "\r\u001b[K     |▌                               | 10kB 24.6MB/s eta 0:00:01\r\u001b[K     |█                               | 20kB 6.1MB/s eta 0:00:01\r\u001b[K     |█▌                              | 30kB 7.4MB/s eta 0:00:01\r\u001b[K     |██                              | 40kB 7.7MB/s eta 0:00:01\r\u001b[K     |██▍                             | 51kB 6.3MB/s eta 0:00:01\r\u001b[K     |███                             | 61kB 5.9MB/s eta 0:00:01\r\u001b[K     |███▍                            | 71kB 6.0MB/s eta 0:00:01\r\u001b[K     |███▉                            | 81kB 6.3MB/s eta 0:00:01\r\u001b[K     |████▍                           | 92kB 6.3MB/s eta 0:00:01\r\u001b[K     |████▉                           | 102kB 6.1MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 112kB 6.1MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 122kB 6.1MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 133kB 6.1MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 143kB 6.1MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 153kB 6.1MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 163kB 6.1MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 174kB 6.1MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 184kB 6.1MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 194kB 6.1MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 204kB 6.1MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 215kB 6.1MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 225kB 6.1MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 235kB 6.1MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 245kB 6.1MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 256kB 6.1MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 266kB 6.1MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 276kB 6.1MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 286kB 6.1MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 296kB 6.1MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 307kB 6.1MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 317kB 6.1MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 327kB 6.1MB/s eta 0:00:01\r\u001b[K     |████████████████                | 337kB 6.1MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 348kB 6.1MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 358kB 6.1MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 368kB 6.1MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 378kB 6.1MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 389kB 6.1MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 399kB 6.1MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 409kB 6.1MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 419kB 6.1MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 430kB 6.1MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 440kB 6.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 450kB 6.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 460kB 6.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 471kB 6.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 481kB 6.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 491kB 6.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 501kB 6.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 512kB 6.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 522kB 6.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 532kB 6.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 542kB 6.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 552kB 6.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 563kB 6.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 573kB 6.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 583kB 6.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 593kB 6.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 604kB 6.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 614kB 6.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 624kB 6.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 634kB 6.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 645kB 6.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 655kB 6.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 665kB 6.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 675kB 6.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 15.5MB/s \n",
            "\u001b[?25hCollecting tokenizers==0.7.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/14/e5/a26eb4716523808bb0a799fcfdceb6ebf77a18169d9591b2f46a9adb87d9/tokenizers-0.7.0-cp36-cp36m-manylinux1_x86_64.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 30.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.4)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 59.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.9)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.4.5.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (1.12.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.15.1)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893260 sha256=bd0c863635f786938421dce3bd260d35edecb5830911125b7dcea4a6201c1259\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sentencepiece, tokenizers, sacremoses, transformers\n",
            "Successfully installed sacremoses-0.0.43 sentencepiece-0.1.91 tokenizers-0.7.0 transformers-2.11.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d_nn3RYMncMX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset_name = \"\"\n",
        "speaker_model_name = \"model3\"\n",
        "listener_model_name = \"model4\"\n",
        "model_type = \"emotion\" #pos_neg or emotion"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c2FQw1KNn1fM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "64189322-6382-437f-aca7-082b88d74497"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Get the GPU device name.\n",
        "device_name = tf.test.gpu_device_name()\n",
        "\n",
        "# The device name should look like the following:\n",
        "if device_name == '/device:GPU:0':\n",
        "    print('Found GPU at: {}'.format(device_name))\n",
        "else:\n",
        "    raise SystemError('GPU device not found')\n",
        "\n",
        "import torch\n",
        "\n",
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():    \n",
        "\n",
        "    # Tell PyTorch to use the GPU.    \n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n",
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla P4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "renu1EMVoOZX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "7cd664f4-a367-43f4-e600-6d8ac25a2277"
      },
      "source": [
        "import json\n",
        "with open(\"Data/data_sample_10.json\") as infile:\n",
        "  data = json.load(infile)\n",
        "print(data['1022'])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'prompt': 'We (family friends) planned a holiday trip to go for the last weekend. I was preparing for that like packing dress and getting ready to it. Unfortunately one of my cousin was unable to come due to his personal reasons. So we just cancelled the trip. I was feeling sad for this trip cancellation. ', 'emotion': 'sad', 'dialog': [{'speaker': 43, 'utterance': 'My holiday trip has cancelled. I was feeling low for it. '}, {'speaker': 167, 'utterance': 'That is bad news and hard to deal with.'}, {'speaker': 43, 'utterance': 'yeah. Waiting for the next holiday.'}, {'speaker': 167, 'utterance': 'I sure hope you have a wonderful next Holiday trip very soon.'}, {'speaker': 43, 'utterance': 'thank you! have a nice day'}]}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AnfbzV_etiqK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "0d810630-90e8-4341-de26-f4b7b5b37132"
      },
      "source": [
        "print(data.keys())\n",
        "print(data['2103'])"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dict_keys(['1022', '2103', '4072', '9710', '11290', '11572', '13042', '13485', '18577', '21184'])\n",
            "{'prompt': 'My cousin bought a really pretty shirt that I had been wanting.', 'emotion': 'jealous', 'dialog': [{'speaker': 226, 'utterance': 'My cousin bought a really pretty shirt that I had been wanting'}, {'speaker': 10, 'utterance': 'My cousin bought a really pretty shirt that I had been wanting'}, {'speaker': 226, 'utterance': 'that is not fun_comma_ does that mean you cannot get it now?'}, {'speaker': 10, 'utterance': \"No I can but I didn't want her to have it and not me.\"}, {'speaker': 226, 'utterance': 'that is no fun_comma_ does that mean you cannot buy it now?'}, {'speaker': 10, 'utterance': \"No I can but I didn't want her to have it and not me.\"}]}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bWKkiQeDoPon",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open(\"Data/data_fixed_train.json\",\"r\") as infile:\n",
        "  data = json.load(infile)\n",
        "  with open(\"Data/data_complement_analysis.csv\",\"w\") as outfile:\n",
        "    outfile.write(\"emotion|speaker_utterance|listener_utterance\\n\")\n",
        "    for key in data.keys():\n",
        "      dialog = data[key]['dialog']\n",
        "      emotion = data[key]['emotion']\n",
        "      i = 0\n",
        "      while i < len(dialog):\n",
        "        speaker_utterance = str(dialog[i]['utterance']).replace(\"|\",\"\").replace(\"_comma_\",\",\")\n",
        "        listener_utterance = str(dialog[i+1]['utterance']).replace(\"|\",\"\").replace(\"_comma_\",\",\") if i + 1 < len(dialog) else \"\"\n",
        "        line = \"%s|%s|%s\\n\" % (emotion, speaker_utterance, listener_utterance)\n",
        "        outfile.write(line)\n",
        "        #print(line)\n",
        "        i += 2"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}